<div style="text-align:center">
<!-- <img src="https://big-cheng.com/k2/k2.png" alt="k2-logo" width="200"/> -->
<h2>üìà CFGPT: Chinese Financial Assistant with Large Language Model</h2>
</div>


<a href='https://arxiv.org/abs/2309.10654'><img src='https://img.shields.io/badge/Paper-ArXiv-C71585'></a> 
<a href='https://huggingface.co/TongjiFinLab/CFGPT1-pt-7B'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging Face-CFGPT(pt)-red'></a> 
<a href='https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-LoRA'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging Face-CFGPT(sft%20LoRA)-red'></a> 
<a href='https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-Full'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging Face-CFGPT(sft%20Full)-red'></a> 

English | [ÁÆÄ‰Ωì‰∏≠Êñá](README-zh.md)

# Introduction

We introduce **CFGPT**, an open-source language model trained by firstly further pretraining general LLMs on collected and cleaned Chinese finance text data (CFData-pt), including financial domain-specific data (announcement, finance articles, finance exams, finance news, finance research papers) and general data (Wikipedia), and secondly fine-tuning with knowledge-intensive instruction tuning data (CFData-sft). 
As for preliminary evaluation, we use CFBenchmark-Basic. 
CFGPT outperforms the baselines on objective and subjective tasks compared to several baseline models with similar parameters. 

In this repository, we will share the following models and code.

- We release CFGPT1 (7B) in three parts:
  - [Pretrained Model](https://huggingface.co/TongjiFinLab/CFGPT1-pt-7B): Full model weights after further pretraining with the chinese finance text corpus to comply with the InternLM model license. 
  - [Supervised Finetuned Model (Lora)](https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-LoRA): Adapter model weights trained by PEFT (LoRA).
  - [Supervised Finetuned Model (Full)](https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-Full): Full model trained weights based on the pretrained model.

- We release the [CFBenchmark](https://github.com/TongjiFinLab/CFBenchmark), a Chinese financial assistant benhmark for large language model. The basic version of CFBenchmark includes 3917 financial texts spanning three aspects and eight tasks, for the evaluation of the financial text processing capability of LLMs in Chinese financial market.

- We release the code of further pretrain and instruction tuning of CFGPT.

- We further provide several samples about our CFData-sft.

***The following is the overview of training CFGPT:***

<div align="center">
<img align="center" src=./figs/CFGPT-Training.svg width="100%"/>
</div>


# Content

- [Quick Start](#quick-start)
- [Data](#data)
- [Code](#code)
- [Cases](#cases)
- [Benchmark](#benchmark)
- [Acknowledgements](#acknowledgements)
- [To-Do List](#to-do-list)
- [License](#license)
- [Citation](#citation-arxiv)

# Quick Start

**1. Prepare the code and the environment**

Clone our repository, create a Python environment, and activate it via the following command

```bash
git clone https://github.com/TongjiFinLab/CFGPT.git
cd CFGPT
conda create -n env_name python=3.10   
source activate env_name 
pip install -r requirements.txt
```

**2. Prepare the pretrained CFGPT1**

The CFGPT1 consists of three parts: a pretrain model, continued pretraining InternLM-7B on our CFData-pt, an adapter model (trained via PEFT on our CFData-sft), and a Full-finetuned model trained base on the pretrain model.

|                        Pretrain model                        |                        Adapter model                         |                        Full SFT Model                        |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| [CFGPT1-pt-7B](https://huggingface.co/TongjiFinLab/CFGPT1-pt-7B) | [CFGPT1-sft-7B-lora](https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-LoRA) | [CFGPT1-sft-7B-full](https://huggingface.co/TongjiFinLab/CFGPT1-sft-7B-Full) |

**3. Use CFGPT1-sft-7B-LoRA**

```python
from transformers import AutoModel, AutoTokenizer
from peft import PeftModel
base_model = 'TongjiFinLab/CFGPT1-pt-7B'
lora_weights = 'TongjiFinLab/CFGPT1-sft-7B-LoRA'
device_map = 'cuda:0'
tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
model = AutoModel.from_pretrained(
    base_model,
    trust_remote_code=True,
    device_map=device_map,
    torch_dtype=torch.bfloat16
)
model = PeftModel.from_pretrained(
    model,
    lora_weights,
    device_map=device_map,
)
model = model.eval()
inputs = tokenizer("""‰Ω†ÊòØ‰∏ÄÂêçÈáëËûç‰ªé‰∏öËÄÖÔºåËØ∑ÂØπËøôÁØáÊñ∞ÈóªËøõË°åÊÉÖÊÑüÂàÜÊûê„ÄÇËØ∑‰ªéÔºà‰∏≠ÊÄß„ÄÅÁßØÊûÅ„ÄÅÊ∂àÊûÅÔºâ‰∏≠ÈÄâÂèñÁ≠îÊ°à„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºöÊåñË¥ùÂø´ËÆØÔºöÁâπÊ≠•ÂõΩÈôÖÂèëÂ∏É2023Âπ¥Á¨¨‰∫åÂ≠£Â∫¶‰∏≠ÂõΩÂÜÖÂú∞‰∏öÂä°Ëê•ËøêÁä∂ÂÜµÔºåÊä´Èú≤Êà™Ëá≥2023Âπ¥6Êúà30Êó•Ê≠¢3‰∏™ÊúàÈõ∂ÂîÆÈîÄÂîÆÂÆûÁé∞È´òÂèå‰ΩçÊï∞ÂêåÊØîÂ¢ûÈïø(ÂåÖÊã¨Á∫ø‰∏äÁ∫ø‰∏ãÊ∏†ÈÅì)ÔºåÈõ∂ÂîÆÊäòÊâ£Ê∞¥Âπ≥Á∫¶‰∏É‰∫îÊäò„ÄÇÂêåÊó∂Ôºå2022Âπ¥7ÊúàMSCIÈ¶ñÊ¨°‰∫à‰ª•ÁâπÊ≠•ESGËØÑÁ∫ßÔºå‰∏ÄÂπ¥ÂêéËØÑÁ∫ßË°®Áé∞Âç≥ËøéÊù•ÊèêÂçá„ÄÇÊòéÊôüMSCI‰∏äË∞ÉÁâπÊ≠•ESGËØÑÁ∫ßÔºåÁî±‚ÄúBB‚ÄùÂçáËá≥‚ÄúBBB‚Äù„ÄÇ\nÂõûÁ≠îÔºö""", return_tensors='pt').to(device_map)
pred = model.generate(**inputs, max_new_tokens=64, do_sample=False, repetition_penalty=1.0)
print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True).split('ÂõûÁ≠îÔºö')[1])
```

**4. Use CFGPT1-sft-7B-Full**

```python
from transformers import AutoModel, AutoTokenizer
base_model = 'TongjiFinLab/CFGPT1-sft-7B-Full'
device_map = 'cuda:0'
tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
model = AutoModel.from_pretrained(
    base_model,
    trust_remote_code=True,
    device_map=device_map,
    torch_dtype=torch.bfloat16
)
model = model.eval()
inputs = tokenizer("""‰Ω†ÊòØ‰∏ÄÂêçÈáëËûç‰ªé‰∏öËÄÖÔºåËØ∑ÂØπËøôÁØáÊñ∞ÈóªËøõË°åÊÉÖÊÑüÂàÜÊûê„ÄÇËØ∑‰ªéÔºà‰∏≠ÊÄß„ÄÅÁßØÊûÅ„ÄÅÊ∂àÊûÅÔºâ‰∏≠ÈÄâÂèñÁ≠îÊ°à„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºöÊåñË¥ùÂø´ËÆØÔºöÁâπÊ≠•ÂõΩÈôÖÂèëÂ∏É2023Âπ¥Á¨¨‰∫åÂ≠£Â∫¶‰∏≠ÂõΩÂÜÖÂú∞‰∏öÂä°Ëê•ËøêÁä∂ÂÜµÔºåÊä´Èú≤Êà™Ëá≥2023Âπ¥6Êúà30Êó•Ê≠¢3‰∏™ÊúàÈõ∂ÂîÆÈîÄÂîÆÂÆûÁé∞È´òÂèå‰ΩçÊï∞ÂêåÊØîÂ¢ûÈïø(ÂåÖÊã¨Á∫ø‰∏äÁ∫ø‰∏ãÊ∏†ÈÅì)ÔºåÈõ∂ÂîÆÊäòÊâ£Ê∞¥Âπ≥Á∫¶‰∏É‰∫îÊäò„ÄÇÂêåÊó∂Ôºå2022Âπ¥7ÊúàMSCIÈ¶ñÊ¨°‰∫à‰ª•ÁâπÊ≠•ESGËØÑÁ∫ßÔºå‰∏ÄÂπ¥ÂêéËØÑÁ∫ßË°®Áé∞Âç≥ËøéÊù•ÊèêÂçá„ÄÇÊòéÊôüMSCI‰∏äË∞ÉÁâπÊ≠•ESGËØÑÁ∫ßÔºåÁî±‚ÄúBB‚ÄùÂçáËá≥‚ÄúBBB‚Äù„ÄÇ\nÂõûÁ≠îÔºö""", return_tensors='pt').to(device_map)
pred = model.generate(**inputs, max_new_tokens=64, do_sample=False, repetition_penalty=1.0)
print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True).split('ÂõûÁ≠îÔºö')[1])
```

- **More detail are in `./code/test`**

# Data

In this repo, we share the samples of CFData:

- CFData: `./data`

  The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised finetuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decisionmaking with 1.5M instruction pairs and 1.5B tokens in total.


## Further pretrain

The pre-training dataset consists of 591 million documents and 193 billion tokens, including six sub-datasets

* CFData-CP (6.24%): 39 thousand corporate prospectus with 13 billion tokens;
* CFData-CA (12.28%): 6 million corporate announcements with 17 billion tokens; 
* CFData-RR (2.51% ): 392 thousand research reports with 3 billion tokens; 
* CFData-FN (18.70%): 82 million financial news with 26 billion tokens; 
* CFData-SM (60.15%): 495 million social medias and 84 billion tokens; 
* CFData-Wiki (0.09%): 255 thousand Wikipedia content with 137 million tokens.

We sample a financial text sub-corpus from CFData-pt for further pretraining on InternLM-7B consists of 13.7 billion tokens from a large amount of Chinese financial data and analytics and a small amount of general-purpose text, such as announcements, research reports, social media content, financial news articles, and Wikipedia. And they were mainly collected by ourselves.

## Supervised Finetuning

The supervised fine-tuning dataset consist 1.6 million instructions pairs and 1.5 billion tokens, including six financial tasks: 

* CFData-SA (5.69% ): 120 thousand instances with 86 million tokens for sentiment analysis; 
* CFData-RS (50.60%): 369 thousand instances and 765 million tokens for report summary; 
* CFData-ED (22.69% ): 490 thousand instances with 343 million tokens for event detection; 
* CFData-TD (12.37%): 369 thousand instances and 187 million tokens for topic decomposition; 
* CFData-QA (0.39%): 12 thousand instances and 6 million tokens for question-answering; 
* CFData-SP (8.27%): 212 thousand instances and 125 million tokens for stock moving prediction.

We employ high-quality domain specific data to achieve finance domain adaptation during supervised finetuing. The dataset includes six financial datasets to reflect different aspects of financial analysis and decision-making, which include sentiment analysis, event detection, report summarization, topic decomposition, question answering, and stock movement prediction. 
CFData-sft provides much text information in the financial domain, allowing a FinLLM to learn from different of sources.
Considering requirement in reality, we reform these financial supervised finetuning dataset into ten tasks.

The details are as follows:

| Task       | Task Description                                             | Dataset   | Size |
| ---------- | ------------------------------------------------------------ | --------- | ---- |
| Sentiment  | Identify the sentiment associated with financial document    | CFData-SA | 13K  |
| Summary    | Generate a content summary based on the provided financial document | CFData-RS | 18K  |
| Risk       | Generate risk alerts based on the provided financial document | CFData-RS | 20K  |
| Suggestion | Generate investment recommendations based on the provided financial document | CFData-RS | 18K  |
| Event      | Identify the event categories associated with financial document | CFData-ED | 12K  |
| Industry   | Identify the industry categories associated with financial document | CFData-ED | 14K  |
| Company    | Identify the company names associated with financial document | CFData-ED | 12K  |
| Product    | Identify the product names associated with financial document | CFData-ED | 21K  |
| Exam       | Answer true-false questions related to finance question      | CFData-QA | 16K  |
| Stock      | Predict stocks future movement                               | CFData-SP | 15K  |


Due to the data agreement, we cannot publicly release the full version of CFData. The researchers could read the sample case of [CFData](./data)

# Code

## Further Pretrain

The training script is **`./code/train/pretrain`**

```bash
deepspeed --include localhost:0,1,2,3,4,5,6,7 --master_port 60002 bf_16_parallel_train.py --config bf_16_parallel_train.yml > bf_16_parallel_train.log 2>&1
```

<!-- ![loss curve](https://big-cheng.com/k2/loss_curve.png) -->

<div align="center">
<img align="center" src=./figs/CFGPT-Training-loss.svg width="100%"/>
</div>


The trainer parameters we use are in **`./code/train/pretrain/bf_16_parallel_train.yml`**: 

```
# basic setting
model_name: path/of/your/further/pretrain/model
dataset: path/to/your/further/pretrain/dataset
deepspeed: ./ds_config.json
seed: 42
max_seq_length: 2048

# train setting 
output_dir: ./bf_16_parallel_train
logging_steps: 10
num_train_epochs: 1
per_device_train_batch_size: 2
gradient_accumulation_steps: 16
learning_rate: 2.0e-4
weight_decay: 0.01
warmup_steps: 1000
save_steps: 1000
fp16: 0
bf16: 1
torch_compile: 0
save_strategy: steps
remove_unused_columns: 0
```

The deepspeed parameters we use are in **`./code/train/pretrain/ds_config.json`**: 

```
{
    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false,
    "optimizer": {
        "type": "AdamW",
        "params": {
          "lr": "auto",
          "betas": "auto",
          "eps": "auto",
          "weight_decay": 0.01
          }
        },
     "scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "total_num_steps": "auto",
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },
    "bf16": {
        "enabled": true
    },
    "zero_optimization": {
        "stage": 1,
        "reduce_bucket_size": 5e8
    }
}
```

## Supervised Finetuning

The training script is in **`./code/train/lora`**. Here we use the lora-bf16 as illustrations.

```bash
deepspeed --include localhost:6,7 --master_port 60005 lora_bf_16_parallel_train.py --config lora_bf_16_parallel_train.yml > lora_bf_16_parallel_train.log 2>&1
```

The trainer parameters we use are in **`./code/train/lora/bf16/bf_16_parallel_train.yml`**: 

```
# basic setting
model_name: path/of/your/supervised/finetuning/model
dataset: path/to/your/supervised/finetuning/dataset
dataset_eval: path/to/your/evaluate/dataset
deepspeed: ./ds_config.json
seed: 42
max_seq_length: 2048

# train setting 
output_dir: ./lora_bf_16_parallel_train
num_train_epochs: 1
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 2.0e-4
weight_decay: 0.01
warmup_steps: 500
fp16: 0
bf16: 1
torch_compile: 0
save_strategy: steps
save_steps: 500
evaluation_strategy: steps
eval_steps: 100
logging_steps: 10
remove_unused_columns: 0

# lora setting
rank: 64
lora_alpha: 16
lora_dropout: 0.05
target_modules: ['k_proj', 'o_proj', 'down_proj', 'v_proj', 'q_proj', 'gate_proj', 'up_proj']
bias: 'none'

# restart info
resume_from_checkpoint: null
```

The deepspeed parameters we use are in **`./code/train/lora/bf16/ds_config.json`**: 

```
{
    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false,

    "optimizer": {
      "type": "AdamW",
      "params": {
        "lr": "auto",
        "betas": "auto",
        "eps": "auto",
        "weight_decay": "auto"
        }
      
      },
    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },
    "bf16": {
      "enabled": true
    },
    "zero_optimization": {
        "stage": 0
    }
}
```


# Cases

- **Sentiment:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏ÄÂêçÈáëËûç‰ªé‰∏öËÄÖÔºåËØ∑ÂØπËøôÁØáÊñ∞ÈóªËøõË°åÊÉÖÊÑüÂàÜÊûê„ÄÇËØ∑‰ªéÔºà‰∏≠ÊÄß„ÄÅÁßØÊûÅ„ÄÅÊ∂àÊûÅÔºâ‰∏≠ÈÄâÂèñÁ≠îÊ°à„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºöÊåñË¥ùÂø´ËÆØÔºöÁâπÊ≠•ÂõΩÈôÖÂèëÂ∏É2023Âπ¥Á¨¨‰∫åÂ≠£Â∫¶‰∏≠ÂõΩÂÜÖÂú∞‰∏öÂä°Ëê•ËøêÁä∂ÂÜµÔºåÊä´Èú≤Êà™Ëá≥2023Âπ¥6Êúà30Êó•Ê≠¢3‰∏™ÊúàÈõ∂ÂîÆÈîÄÂîÆÂÆûÁé∞È´òÂèå‰ΩçÊï∞ÂêåÊØîÂ¢ûÈïø(ÂåÖÊã¨Á∫ø‰∏äÁ∫ø‰∏ãÊ∏†ÈÅì)ÔºåÈõ∂ÂîÆÊäòÊâ£Ê∞¥Âπ≥Á∫¶‰∏É‰∫îÊäò„ÄÇÂêåÊó∂Ôºå2022Âπ¥7ÊúàMSCIÈ¶ñÊ¨°‰∫à‰ª•ÁâπÊ≠•ESGËØÑÁ∫ßÔºå‰∏ÄÂπ¥ÂêéËØÑÁ∫ßË°®Áé∞Âç≥ËøéÊù•ÊèêÂçá„ÄÇÊòéÊôüMSCI‰∏äË∞ÉÁâπÊ≠•ESGËØÑÁ∫ßÔºåÁî±‚ÄúBB‚ÄùÂçáËá≥‚ÄúBBB‚Äù„ÄÇ

  - **Answer:** 

    >ÁßØÊûÅ

- **Summary:**

  - **Question:** 

    >‰Ωú‰∏∫‰∏ÄÂêçÈáëËûçÊäïËµÑÂàÜÊûê‰∏ìÂÆ∂Ôºå‰Ω†ÈúÄË¶ÅÂàÜÊûêÂπ∂ÊÄªÁªìÊù•Ëá™‰∏çÂêåÂà∏ÂïÜÁöÑÁ†îÁ©∂Êä•Âëä„ÄÇËØ∑‰Ω†Á™ÅÂá∫ËØ•Á†îÊä•ÁöÑÂàõÊñ∞ÁÇπÂíåÂ∏ÇÂú∫Ê¥ûËßÅ„ÄÇÁ†îÊä•ÂÜÖÂÆπÔºö‰∫ã‰ª∂ÔºöÂÖ¨Âè∏4Êúà26Êó•ÂèëÂ∏É2022Âπ¥Âπ¥Â∫¶Êä•ÂëäÂèä2023Âπ¥‰∏ÄÂ≠£Êä•Ôºå2022Âπ¥ÂÆûÁé∞Ëê•Êî∂10.71‰∫øÂÖÉÔºåÂêåÊØîÂ¢ûÈïø21.89%ÔºõÂΩíÊØçÂáÄÂà©Ê∂¶5.26‰∫øÂÖÉÔºåÂêåÊØîÂ¢ûÈïø19.95%ÔºõÊâ£ÈùûÂáÄÂà©Ê∂¶5.05‰∫øÂÖÉÔºåÂêåÊØîÂ¢ûÈïø16.32%„ÄÇ2023Âπ¥Q1ÂÆûÁé∞Ëê•Êî∂2.00‰∫øÂÖÉÔºåÂêåÊØî‰∏ãÈôç22.90%ÔºåÁéØÊØî‰∏ãÈôç31.59%ÔºõÂΩíÊØçÂáÄÂà©Ê∂¶0.75‰∫øÂÖÉÔºåÂêåÊØî‰∏ãÈôç38.88%ÔºåÁéØÊØî‰∏ãÈôç48.40%ÔºõÊâ£ÈùûÂáÄÂà©Ê∂¶0.71‰∫øÂÖÉÔºåÂêåÊØî‰∏ãÈôç41.52%ÔºåÁéØÊØî‰∏ãÈôç47.81%„ÄÇ
    >2022Âπ¥ÔºåÂÖ¨Âè∏ÁßØÊûÅ‰ºòÂåñ‰∫ßÂìÅÁªìÊûÑÔºåÊåÅÁª≠Âä†Âº∫Âú®Êñ∞ËÉΩÊ∫êÂíåÂ∑•‰∏öÈ¢ÜÂüüÁöÑÊµãËØïÂ∏ÉÂ±ÄÔºåÈÉ®ÂàÜÊäµÊ∂à‰∫ÜÊ∂àË¥πÁ±ªËäØÁâáÈúÄÊ±Ç‰∏ãÊªëÁöÑÂΩ±ÂìçÔºåÂä©ÂäõÂÖ®Âπ¥‰∏öÁª©Á®≥Ê≠•Â¢ûÈïø„ÄÇ2023Âπ¥Q1ÂèóË°å‰∏öÊ≥¢Âä®Âèä‰∫ßÂìÅÁªìÊûÑÂèòÂåñÂΩ±ÂìçÔºå‰∏ªËê•‰∏öÂä°ÊØõÂà©ÊúâÊâÄ‰∏ãÈôçÔºõÂêåÊó∂ÂÖ¨Âè∏Â¢ûÂä†‰∫ÜÂ∏ÇÂú∫ÂºÄÊãìÂíåÁ†îÂèëÊäïÂÖ•ÔºåËá¥‰ΩøÂáÄÂà©Ê∂¶Áü≠ÊúüÊâøÂéã„ÄÇÂÖ¨Âè∏2022Âπ¥ÊØõÂà©Áéá‰∏∫76.88%ÔºåÂêåÊØî‰∏ãÈôç3.34pctÔºõÂáÄÂà©Áéá‰∏∫49.16%ÔºåÂêåÊØî‰∏ãÈôç0.80pct„ÄÇ2023Âπ¥Q1ÊØõÂà©Áéá‰∏∫69.68%ÔºåÂêåÊØî‰∏ãÈôç10.35pctÔºåÁéØÊØî‰∏ãÈôç6.57pctÔºõÂáÄÂà©Áéá‰∏∫37.33%ÔºåÂêåÊØî‰∏ãÈôç9.76pctÔºåÁéØÊØî‰∏ãÈôç12.17pct„ÄÇË¥πÁî®ÊñπÈù¢ÔºåQ1ÈîÄÂîÆ„ÄÅÁÆ°ÁêÜ„ÄÅÁ†îÂèë„ÄÅË¥¢Âä°Ë¥πÁî®ÁéáÂàÜÂà´‰∏∫14.28%/7.15%/16.58%/-3.49%ÔºåÂêåÊØîÂèòÂä®ÂàÜÂà´‰∏∫5.73/0.88/6.40/-1.23pct„ÄÇ
    >ÂÖ¨Âè∏‰∏∫ÂõΩÂÜÖÊ®°ÊãüÂíåÊ∑∑ÂêàÊµãËØïÈ¢ÜÂüüÁöÑ‰∏ªÂäõÊµãËØïÂπ≥Âè∞‰æõÂ∫îÂïÜÔºåÂêåÊó∂‰πüÂú®ÂàÜÁ´ãÂô®‰ª∂ÂíåÂäüÁéáÁ±ªÂô®‰ª∂ÊµãËØïÈ¢ÜÂüüÂèñÂæóËâØÂ•ΩËøõÂ±ï„ÄÇÂÖ¨Âè∏STS8300Êú∫Âûã‰∏ªË¶ÅÂ∫îÁî®‰∫éÊõ¥È´òÂºïËÑöÊï∞„ÄÅÊõ¥È´òÊÄßËÉΩ„ÄÅÊõ¥Â§öÂ∑•‰ΩçÁöÑÁîµÊ∫êÁÆ°ÁêÜÁ±ªÂíåÊ∑∑Âêà‰ø°Âè∑ÈõÜÊàêÁîµË∑ØÊµãËØïÔºå‰∫ßÂìÅÁöÑÂπ≥Âè∞ÂåñËÆæËÆ°‰ΩøÂÖ∂ÂÖ∑Â§áËâØÂ•ΩÁöÑÂèØÊâ©ÂÖÖÊÄßÂíåÂÖºÂÆπÊÄßÔºåÂèØ‰ª•Êõ¥Â•ΩÈÄÇÂ∫îË¢´ÊµãËØïËäØÁâáÁöÑÊõ¥Êñ∞ÂíåËø≠‰ª£„ÄÇ2022Âπ¥ÔºåSTS8300Âπ≥Âè∞ÁöÑÂá∫Ë¥ßÈáè‰øùÊåÅËæÉÈ´òÂ¢ûÈÄüÔºåË£ÖÊú∫ÈáèÁ®≥ÂÆöÂ¢ûÂä†ÔºåÂÆ¢Êà∑ÁîüÊÄÅÂúàÊûÑÂª∫ËøõÂ±ïÈ°∫Âà©ÔºåÂÜÖÈÉ®ËµÑÊ∫êÊùøÂç°Âä†ÈÄüËø≠‰ª£ÔºåÂ∫îÁî®ËåÉÂõ¥‰∏çÊñ≠ÊãìÂ±ï„ÄÇÂÖ¨Âè∏Ê≠£Âú®Á†îÂèëÂíåÂÇ®Â§áÊñ∞‰∏Ä‰ª£Âπ≥Âè∞ÂûãÊµãËØïËÆæÂ§áÔºåËØ•ËÆæÂ§áÂ∞ÜÊã•ÊúâÊõ¥Âø´ÁöÑÊµãËØïÈ¢ëÁéáÂíåÊõ¥È´òÁöÑÊµãËØïÊïàÁéáÔºåÂèØË¶ÜÁõñÁöÑÊµãËØïËåÉÂõ¥Êõ¥Â§ß„ÄÇÈöèÁùÄSTS8300Â∏ÇÂú∫‰ªΩÈ¢ùÁöÑÊåÅÁª≠ÊèêÂçáÔºåÊñ∞ÂìÅÁ†îÂèëÁ®≥Ê≠•Êé®ËøõÔºåÊúâÊúõÊâìÂºÄ‰∏öÁª©ÊàêÈïøÂ§©Ëä±Êùø„ÄÇ
    >ÂÖ¨Âè∏Âú®‰∏çÊñ≠Â§ØÂÆûÊ®°ÊãüÂíåÊï∞Ê®°Ê∑∑ÂêàÈ¢ÜÂüüÁöÑ‰ºòÂäøÁöÑÂêåÊó∂ÔºåÂØπÁ¨¨‰∏â‰ª£ÂçäÂØº‰ΩìÊµãËØïÈ¢ÜÂüü„ÄÅÂäüÁéáÊ®°ÂùóÊµãËØï‰ª•ÂèäSoCÁ≠âÊñ∞ÂÖ¥È¢ÜÂüüËøõË°å‰∫ÜÂâçÁûªÂ∏ÉÂ±Ä„ÄÇÂΩìÂâçÂÖ¨Âè∏Âú®Ê∞ÆÂåñÈïìÊµãËØïÈ¢ÜÂüüÂ∑≤ÂèñÂæóÈ¢ÜÂÖà‰ºòÂäøÔºå2022Âπ¥Âú®ÂõΩÂÆ∂ÂèåÁ¢≥ÊîøÁ≠ñÊé®Âä®‰∏ãÔºåÊñ∞ËÉΩÊ∫êÊ±ΩËΩ¶„ÄÅÂÖâ‰ºè‰∫ß‰∏öÂëàÁé∞ËæÉÈ´òÁöÑÊôØÊ∞îÂ∫¶ÔºåÂÖ¨Âè∏Â§ßÂäüÁéáIGBTÂíåÁ¢≥ÂåñÁ°ÖÊµãËØïÈ¢ÜÂüüÂºÄÂßãÈÄêÊ∏êÊîæÈáè„ÄÇÂÆ¢Êà∑ÊãìÂ±ïÊñπÈù¢ÔºåÂÖ¨Âè∏Â∑≤ËøõÂÖ•ÂõΩÈôÖÂ∞ÅÊµãÂ∏ÇÂú∫‰æõÂ∫îÂïÜ‰ΩìÁ≥ªÔºåÂú®‰∏≠ÂõΩÂè∞Êπæ„ÄÅ‰∏úÂçó‰∫ö„ÄÅÊó•Êú¨„ÄÅÈü©ÂõΩ„ÄÅÊ¨ßÊ¥≤„ÄÅÁæéÂõΩ„ÄÅÂçóÈùûÂíåÂåóÈùûÁ≠âÂõΩÂÆ∂ÊàñÂú∞Âå∫ÂùáÊúâË£ÖÊú∫ÔºõÂÖ¨Âè∏ÂØπÂõΩÂÜÖÁöÑËÆæËÆ°ÂÖ¨Âè∏ÂíåIDM‰ºÅ‰∏ö‰øùÊåÅÂÖ®Èù¢Ë¶ÜÁõñÔºåÁ°Æ‰øùÂú®ÈïøÊúüÁ´û‰∫â‰∏≠‰øùÊåÅÈ¢ÜÂÖàÂú∞‰ΩçÔºåÂêåÊó∂ÊåÅÁª≠ÊãìÂ±ïÊµ∑Â§ñÂÆ¢Êà∑ÔºåÂ¶ÇÊÑèÊ≥ïÂçäÂØº‰Ωì„ÄÅÂÆâÊ£ÆÁæé„ÄÅÂÆâ‰∏ñÂçäÂØº‰ΩìÁ≠âÂùáÂ∑≤Êàê‰∏∫ÂÖ¨Âè∏ÂÆ¢Êà∑„ÄÇ
    >È¶ñÊ¨°Ë¶ÜÁõñÔºåÁªô‰∫à‚ÄúÂ¢ûÊåÅ‚ÄùËØÑÁ∫ßÔºöÂÖ¨Âè∏‰∏ªËê•‰∏öÂä°‰∏∫ÂçäÂØº‰ΩìËá™Âä®ÂåñÊµãËØïÁ≥ªÁªüÁöÑÁ†îÂèëÔºåÁîü‰∫ßÂíåÈîÄÂîÆÔºå‰∏ªË¶Å‰∫ßÂìÅ‰∏∫ÂçäÂØº‰ΩìËá™Âä®ÂåñÊµãËØïÁ≥ªÁªüÂèäÊµãËØïÁ≥ªÁªüÈÖç‰ª∂„ÄÇÂÖ¨Âè∏Êã•ÊúâÊ®°Êãü„ÄÅÊï∞Ê®°Ê∑∑Âêà„ÄÅÂàÜÁ´ãÂô®‰ª∂‰ª•ÂèäÂäüÁéáÊ®°ÂùóÁ≠âÊµãËØïÈ¢ÜÂüüÁöÑËØ∏Â§öÊ†∏ÂøÉÊäÄÊúØÔºåÂåÖÊã¨V/IÊ∫ê„ÄÅÁ≤æÂØÜÁîµÂéãÁîµÊµÅÊµãÈáè„ÄÅÂÆΩÁ¶ÅÂ∏¶ÂçäÂØº‰ΩìÊµãËØïÂíåÊô∫ËÉΩÂäüÁéáÊ®°ÂùóÊµãËØïÁ≠âÔºåÂêåÊó∂ÂØÜÂàáË∑üË∏™ÂçäÂØº‰ΩìË°å‰∏öÁöÑÂèëÂ±ïÊñπÂêëÔºå‰∏çÊñ≠‰∏∫ÂÆ¢Êà∑Êé®Âá∫ÂäüËÉΩÊõ¥ÂÖ®„ÄÅÁ≤æÂ∫¶Êõ¥È´ò„ÄÅÈÄüÂ∫¶Êõ¥Âø´ÁöÑÊµãËØïËÆæÂ§á„ÄÇÊàë‰ª¨ÁúãÂ•ΩÂÖ¨Âè∏Âú®Á¨¨‰∏â‰ª£ÂçäÂØº‰Ωì„ÄÅÂäüÁéá„ÄÅSoCÁ≠âÊñ∞ÂÖ¥È¢ÜÂüüÁöÑÂÖàÂèë‰ºòÂäøÔºåÈöèÁùÄÊñ∞ÂìÅÁöÑÊåÅÁª≠Á†îÂèëÂíåÊé®Âá∫Ôºå‰ª•ÂèäÊµ∑ÂÜÖÂ§ñÂÆ¢Êà∑ÁöÑÊåÅÁª≠ÊãìÂ±ïÔºåÂÖ¨Âè∏‰∏öÁª©ÊúâÊúõÂÆûÁé∞ÈïøÊúüÁ®≥ÂÆöÂ¢ûÈïø„ÄÇÈ¢ÑËÆ°ÂÖ¨Âè∏2023-2025Âπ¥ÂΩíÊØçÂáÄÂà©Ê∂¶ÂàÜÂà´‰∏∫6.13‰∫øÂÖÉ„ÄÅ8.16‰∫øÂÖÉ„ÄÅ10.56‰∫øÂÖÉÔºåEPSÂàÜÂà´‰∏∫6.73„ÄÅ8.96„ÄÅ11.59ÂÖÉÔºåPEÂàÜÂà´‰∏∫39X„ÄÅ29X„ÄÅ23XÔºåÁªô‰∫à‚ÄúÂ¢ûÊåÅ‚ÄùËØÑÁ∫ß„ÄÇ

  - **Answer:** 

    >È´òÂü∫Êï∞ËÉåÊôØ‰∏ã, Q1ÁõàÂà©ËÉΩÂäõÁï•ÈôçÔΩúÊñ∞‰∫ßÂìÅÊúâÂ∫èÊé®Ëøõ, STS8300ÈîÄÈáèÂÜçÂàõ‰Ω≥Áª©ÔΩúËÅöÁÑ¶ÁªÜÂàÜËµõÈÅì, ÊãìÂÆΩÊàêÈïøÁ©∫Èó¥ÔΩúËÆ¢ÂçïÈáäÊîæÂè†Âä†‰∏ãÊ∏∏‰øÆÂ§ç, ÂÖ¨Âè∏‰∏öÁª©ÊòæËëóÂõûÊöñÔΩúÈ´òÈò∂Êú∫ÂûãÁöÑÂá∫Ë¥ßÂ∏¶Âä®Êî∂ÂÖ•Ê∞¥Âπ≥‰∏äÂçá, Êñ∞‰∫ßÂìÅÈÄêÊ≠•ÊàêÁÜüÂ∏¶Êù•Âà©Ê∂¶ÂºπÊÄßÔΩú‰πòÈ£éÊñ∞ËÉΩÊ∫êËµõÈÅì‰∏úÈ£é, Â§öÂÖÉÂåñÁöÑÊàòÁï•Â∏ÉÂ±ÄËøéÊù•Êî∂Ëé∑

- **Risk:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏Ä‰ΩçÈáëËûçÊäïËµÑ‰∏ìÂÆ∂ÔºåËØ∑ÂàÜÊûêËøô‰ªΩÁ†îÊä•‰∏≠ÂèØËÉΩÂ≠òÂú®ÁöÑÊäïËµÑÈ£éÈô©ÔºåÂåÖÊã¨Â∏ÇÂú∫ÂèòÂä®„ÄÅÊîøÁ≠ñË∞ÉÊï¥Á≠âÊñπÈù¢ÁöÑÈ£éÈô©„ÄÇ
    >Á†îÊä•ÂÜÖÂÆπÔºö 
    >„ÄÄ„ÄÄÂÖ¨Âè∏ÂÖ¨ÂëäÁß∞Êãü‰ª•Ëá™ÊúâËµÑÈáëÈ¢ÑËÆ°ÂõûË¥≠ÂÖ¨Âè∏ËÇ°‰ªΩ‰∏çË∂Ö 450 ‰∏áËÇ°ÔºåÂç†ÂÖ¨Âè∏ÁõÆÂâçÂ∑≤ÂèëË°åÊÄªËÇ°Êú¨ 2.01%ÔºåÂõûË¥≠ÈáëÈ¢ùÂú® 7000 ‰∏áÂÖÉËá≥ 13500 ‰∏áÂÖÉ‰πãÈó¥ÔºåÂõûË¥≠‰ª∑Ê†º‰∏çË∂Ö 30 ÂÖÉ/ËÇ°ÔºåÂõûË¥≠ËÇ°‰ªΩÁî®‰∫éËÇ°ÊùÉÊøÄÂä±ÔºåÂõûË¥≠ÊúüÈôêËá™Ëë£‰∫ã‰ºöÂÆ°ËÆÆÈÄöËøáÂõûË¥≠ËÇ°‰ªΩÊñπÊ°à‰πãÊó•Ëµ∑‰∏çË∂ÖËøá 6 ‰∏™Êúà„ÄÇ
    >„ÄÄ„ÄÄ    ÁÇπËØÑÔºö
    >„ÄÄ„ÄÄÊú¨Ê¨°ËÇ°‰ªΩÂõûË¥≠‰ΩìÁé∞ÂÖ¨Âè∏ÂØπÊú™Êù•ÂèëÂ±ïÂâçÊôØÁöÑ‰ø°ÂøÉÂèäÂØπÂÖ¨Âè∏‰ª∑ÂÄºÁöÑËÆ§ÂèØÔºå ÊúâÂà©‰∫éÁ®≥ÂÆöÊäïËµÑËÄÖÂØπÂÖ¨Âè∏ËÇ°Á•®ÈïøÊúü‰ª∑ÂÄºÁöÑÈ¢ÑÊúüÔºå ÂõûË¥≠ËÇ°‰ªΩÁî®‰∫éËÇ°ÊùÉÊøÄÂä±ÂèØÂÖÖÂàÜË∞ÉÂä®ÂÖ¨Âè∏Ëë£‰∫ã„ÄÅÈ´òÁÆ°„ÄÅ‰∏≠Â±ÇÁÆ°ÁêÜ‰∫∫ÂëòÂèäÊ†∏ÂøÉÈ™®Âπ≤ÁöÑÁßØÊûÅÊÄßÔºåÂ∞ÜËÇ°‰∏úÂà©Áõä„ÄÅÂÖ¨Âè∏Âà©ÁõäÂíåÊ†∏ÂøÉÂõ¢ÈòüÂà©ÁõäÁªìÂêàÂú®‰∏ÄËµ∑„ÄÇ
    >„ÄÄ„ÄÄ‰∫ßÂìÅÁ´ØÔºö Ë°£Êüú„ÄÅÊú®Èó®Ë¥°ÁåÆÊñ∞‰∏öÁª©Â¢ûÈáèÔºå Ê©±Ë°£Êú®ÂçèÂêåÊïàÂ∫îÈÄêÊ∏êÊòæÁé∞„ÄÇ1Ôºâ ‰∏çÊñ≠ÂºÄÊãìÊñ∞‰∫ßÂìÅÔºåÂ§ØÂÆûÊ©±ÊüúÂü∫Á°Ä„ÄÇ ÂÖ¨Âè∏‰ΩçÂ±ÖÊ©±ÊüúË°å‰∏öÁ¨¨‰∫åÔºå Ê©±Êüú‰∏öÂä°Â∑≤ÂΩ¢ÊàêÂÖ≠Â§ß‰∫ßÂìÅÁ≥ªÂàóÔºåÊà™Ê≠¢ 2018 Âπ¥Â∫ïÊ©±Êüú‰∏ö‰∏ìÂçñÂ∫ó 1487 ÂÆ∂Ôºõ 2ÔºâÂèëÂäõÂÖ®Â±ãÂÆöÂà∂ÔºåË°£Êüú‰∏öÂä°È´òÈÄüÂ¢ûÈïø„ÄÇ 2018 Âπ¥ 8 ÊúàÂÖ¨Âè∏Áî±Êï¥‰ΩìÂé®Êàø„ÄÅÂÆöÂà∂Ë°£ÊüúËΩ¨ÂêëÂÖ®Â±ãÂÆöÂà∂ÔºåÊà™Ê≠¢ 2018 Âπ¥Â∫ïÂÆöÂà∂Ë°£Êüú‰∏ìÂçñÂ∫ó 726 ÂÆ∂Ôºå IKÂÖ®Â±ãÂÆö‰∏ìÂçñÂ∫ó 33 ÂÆ∂„ÄÇ 3ÔºâÂ≠µÂåñÊú®Èó®‰∏öÂä°ÔºåË¥°ÁåÆ‰∏öÁª©Â¢ûÈáè„ÄÇÈÄöËøáÂàáÂÖ•Êú®Èó®Â∏ÇÂú∫ÂèØ‰ª•ÂÆûÁé∞Ê©±Ë°£Êú®ËÅîÂä®ÔºåÊãìÂ±ïÂÖ®Â±ãÂÆöÂà∂ÂÆ∂Â±ÖÂìÅÁ±ªÔºå Êà™Ê≠¢ 2018 Âπ¥Â∫ïÂÖ¨Âè∏Êú®Èó®ÁªèÈîÄÂïÜ 117 ÂÆ∂Ôºå‰∏éÂÖ∂‰ªñÂìÅÁ±ªËûçÂêàÁöÑÈó®Â∫ó 88 ÂÆ∂„ÄÇ
    >„ÄÄ„ÄÄÊ∏†ÈÅìÁ´ØÔºåÈõ∂ÂîÆÈó®Â∫óÊåÅÁª≠ÊãìÂ±ïÔºåÂ§ßÂÆóÂÆ¢Êà∑ÁªìÊûÑ‰ºòÂåñÔºå Âá∫Âè£‰∏öÂä°Âø´ÈÄüÂèëÂ±ï„ÄÇ ÂÖ¨Âè∏ËÆ°Âàí 2019 Âπ¥Êñ∞ÂºÄÊ©±ÊüúÈó®Â∫ó 150 ÂÆ∂„ÄÅ Êú®Èó®Â∫ó 100 ÂÆ∂„ÄÅ ÂÆöÂà∂Ë°£ÊüúÂíåÂÖ®Â±ãÂÆöÂà∂Èó®Â∫ó 350 ÂÆ∂„ÄÇÂ§ßÂÆó‰∏öÂä°ÊñπÈù¢Ôºå‰ºòÂåñÂ§ßÂÆóÂÆ¢Êà∑ÁªìÊûÑÔºåÂ§ßÂÆóÂÆ¢Êà∑Â§ö‰∏∫ÁôæÂº∫Â§¥ÈÉ®Âú∞‰∫ß„ÄÅ‰∏ªÊùø‰∏äÂ∏ÇÂÖ¨Âè∏ÂíåÂú∞Âå∫ÈæôÂ§¥Âú∞‰∫ßÂÖ¨Âè∏Ôºå ÂÖ∂‰∏≠ÁôæÂº∫Âú∞‰∫ßÂÆ¢Êà∑Âç†ÊØîÂ∑≤Ëææ 30%„ÄÇ 2018 Âπ¥ÂÖ¨Âè∏Âá∫Âè£Êî∂ÂÖ•ÂêåÊØî+ 87.26%Ôºå Ôºå ÂàõÊñ∞Êæ≥Ê¥≤ IJF ËÇ°ÊùÉÂêà‰ΩúÊ®°ÂºèÔºå ÊàêÁ´ãÁæéÊ¥≤Â∏ÇÂú∫È°πÁõÆÁªÑÔºå Êé¢Á¥¢ÂÖ®ÁêÉÂåñÂèëÂ±ïË∑ØÂæÑ„ÄÇ
    >„ÄÄ„ÄÄÊàë‰ª¨È¢ÑËÆ°ÂÖ¨Âè∏ 2019-2020 Âπ¥ EPS ÂàÜÂà´‰∏∫ 1.41„ÄÅ 1.61 ÂÖÉÔºåÂØπÂ∫î 2019-2020 Âπ¥ PE ÂàÜÂà´‰∏∫ 13.56„ÄÅ 11.87 ÂÄçÔºå ËÄÉËôëÂÖ¨Âè∏ÂÖ®ÂìÅÁ±ª„ÄÅÂ§öÂìÅÁâåÂ∏ÉÂ±ÄÂ≠ïËÇ≤Êñ∞Ëê•Êî∂Â¢ûÈïøÁÇπÔºå Áª¥ÊåÅ‚Äú‰π∞ÂÖ•‚ÄùËØÑÁ∫ß„ÄÇ

  - **Answer:** 

    >ÊàøÂú∞‰∫ßË∞ÉÊéßÂØºËá¥ÈúÄÊ±ÇÂáèÂº±ÁöÑÈ£éÈô©, ÂéüÊùêÊñôÊàêÊú¨Ê≥¢Âä®ÁöÑÈ£éÈô©Á≠â„ÄÇ

- **Suggestion:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏Ä‰ΩçËµÑÊ∑±ÈáëËûçÊäïËµÑËÄÖÔºåËØ∑Ê†πÊçÆÁ†îÊä•‰∏≠ÁöÑÊäïËµÑÂª∫ËÆÆÔºåÁªôÂá∫ÈÄÇÂêàËØ•ÂÖ¨Âè∏ÁöÑÊäïËµÑËØÑÁ∫ß„ÄÇÁ†îÊä•ÂÜÖÂÆπÔºö
    >ÊäïËµÑË¶ÅÁÇπÔºö
    >‰∏≠ÂõΩÁîµÂΩ±ÊòØË¶ÜÁõñÂÖ®‰∫ß‰∏öÈìæÁöÑÁîµÂΩ±ÈæôÂ§¥ÂÖ¨Âè∏ÔºåÂÆûÊéß‰∫∫ÊòØ‰∏≠ÂΩ±ÈõÜÂõ¢
    >‰∏≠ÂõΩÁîµÂΩ±ÊòØÂõΩÂÜÖÂîØ‰∏Ä‰∏ÄÂÆ∂ÈõÜÁîµÂΩ±Âà∂‰Ωú„ÄÅÂèëË°å„ÄÅÊîæÊò†ÂíåÂΩ±ËßÜÊúçÂä°ÂÖ®‰∫ß‰∏öÈìæË¶ÜÁõñÁöÑ‰∏äÂ∏ÇÂÖ¨Âè∏Ôºå Áî±‰∏≠ÂΩ±ÈõÜÂõ¢Âèä‰∏≠ÂõΩÂõΩÈôÖÁîµËßÜ„ÄÅÂ§ÆÂπø‰º†Â™í„ÄÅÈïøÂΩ±ÈõÜÂõ¢„ÄÅÊ±üËãèÂπøÁîµ„ÄÅÊ≠åÂçéÊúâÁ∫ø„ÄÅÁîµÂπø‰º†Â™í„ÄÅ‰∏≠ÂõΩËÅîÈÄö 7 ÂÆ∂ÂÖ¨Âè∏ÂÖ±ÂêåÂèëËµ∑ËÆæÁ´ã„ÄÇ ÁõÆÂâç‰∏≠ÂΩ±ÈõÜÂõ¢ÊòØÂÖ¨Âè∏ÁöÑÊéßËÇ°ËÇ°‰∏úÂíåÂÆûÈôÖÊéßÂà∂‰∫∫Ôºå Êã•ÊúâÂÖ¨Âè∏ 67.36%ÁöÑËÇ°‰ªΩÔºõ Êà™Ê≠¢ 2018 Âπ¥‰∏âÂ≠£Êä•ÂÖ¨Âè∏ÂâçÂçÅÂ§ßËÇ°‰∏úÊåÅËÇ°ÊØî‰æã‰∏∫ 76.41%Ôºå ÊåÅËÇ°ÈõÜ‰∏≠Â∫¶Áõ∏ÂØπËæÉÈ´ò„ÄÇ
    >ÂÖ¨Âè∏ÂèëË°åÂíåÊîæÊò†‰∏öÂä°ÁöÑÂÆûÂäõÂº∫Ôºå ÂÖ®‰∫ß‰∏öÈìæÁ´û‰∫âÂäõÁ™ÅÂá∫
    >ÂÖ¨Âè∏ÁöÑÁªèËê•‰∏öÂä°ÂÖ®Èù¢Ë¶ÜÁõñÁîµÂΩ±‰∫ß‰∏öÈìæÁöÑ‰∏ä‰∏≠‰∏ãÊ∏∏Ôºå ÂàÜÂà´ÂåÖÊã¨‰∏äÊ∏∏ÁöÑÂΩ±ËßÜÂà∂ÁâáÂà∂‰Ωú‰∏öÂä°„ÄÅ‰∏≠Ê∏∏ÁöÑÁîµÂΩ±ÂèëË°åËê•ÈîÄ‰∏öÂä°‰ª•Âèä‰∏ãÊ∏∏ÁöÑÁîµÂΩ±ÊîæÊò†„ÄÅÂΩ±ËßÜÊúçÂä°‰∏öÂä°„ÄÇÂÖ∂‰∏≠Âú®ÂΩ±ËßÜÂèëË°åËê•ÈîÄ‰∏öÂä°ÊñπÈù¢ÔºåÂÖ¨Âè∏ÊòØÂõΩÂÜÖ‰∏§ÂÆ∂ËøõÂè£ÁâáÂèëË°åÂïÜ‰πã‰∏ÄÔºå ÂÖ∑ÊúâÊûÅÈ´òÁöÑÊîøÁ≠ñÂ£ÅÂûíÂíåÁ´û‰∫âÂäõÔºõÂú®ÁîµÂΩ±ÊîæÊò†‰∏öÂä°ÊñπÈù¢ÔºåÂÖ¨Âè∏ÊéßËÇ°ÁöÑ‰∏≠ÂΩ±Êï∞Â≠ó„ÄÅ‰∏≠ÂΩ±ÊòüÁæé„ÄÅ‰∏≠ÂΩ±ÂçóÊñπÊñ∞Âπ≤Á∫ø‰∏âÂÆ∂Èô¢Á∫øÊòØÂõΩÂÜÖÈô¢Á∫øÈ¢ÜÂüüÁöÑ TOP10Ôºå ÁªºÂêàÁ´û‰∫âÂäõÁ™ÅÂá∫ÔºõÁîµÂΩ±ÊúçÂä°‰∏öÂä°‰∏≠ÔºåÂÖ¨Âè∏Êã•Êúâ‰∏≠ÂõΩÂ∑®ÂπïÁöÑÁ†îÂèë„ÄÅÁîü‰∫ßÂíåÈîÄÂîÆËÉΩÂäõÔºåÊ≠§Â§ñËøòËøõË°åÂΩ±Èô¢ÊîæÊò†ËÆæÂ§áÁöÑÈîÄÂîÆÔºåÂèóÁõä‰∫éËøëÂπ¥Êù•ÂõΩÂÜÖÊñ∞Âª∫ÂΩ±Èô¢ÁöÑÂø´ÈÄüÂ¢ûÈïøÔºåÂÖ¨Âè∏ÁöÑ‰∏≠ÂõΩÂ∑®ÂπïÁ≥ªÁªüÂèëÂ±ïËøÖÈÄü„ÄÇÂõ†Ê≠§‰ªéÂ∏ÉÂ±Ä‰∏äÂàÜÊûêÔºå ‰∏≠ÂõΩÁîµÂΩ±Êó†ËÆ∫ÊòØÂú®ÂçïÈ°π‰∏öÂä°ËøòÊòØÊï¥‰Ωì‰∏öÂä°ÂÆûÂäõÈÉΩÂú®ÂõΩÂÜÖÂ§Ñ‰∫éÁªùÂØπÈæôÂ§¥ÁöÑÂú∞‰ΩçÔºåÁ´û‰∫âÂäõÂíåÁªèËê•Â£ÅÂûíÂçÅÂàÜÊòéÊòæ„ÄÇ
    >ÁîµÂΩ±Ë°å‰∏öÔºö 2019 Âπ¥‰∏äÊò†Â§ßÁâáÈòµÂÆπË±™ÂçéÔºåÈ©±Âä®Â∏ÇÂú∫ÂèëÂ±ï
    >2018 Âπ¥ 1-11 ÊúàÂõΩÂÜÖÁîµÂΩ±ÊÄªÁ•®ÊàøÊî∂ÂÖ• 563.12 ‰∫øÂÖÉÔºå ÂêåÊØîÂ¢ûÈïø 10.96%Ôºå Êï¥‰ΩìË°®Áé∞Âü∫Êú¨Á¨¶ÂêàÈ¢ÑÊúü„ÄÇÊàë‰ª¨È¢ÑËÆ° 2019 Âπ¥ÂÖ®Âπ¥Á•®ÊàøÁªßÁª≠‰øùÊåÅÂπ≥Á®≥Â¢ûÈïøÔºå ËøõÂè£ÁâáÁöÑÁõ∏ÂØπÁ´û‰∫â‰ºòÂäøÊõ¥Âº∫ÔºåÈÄªËæëÂú®‰∫éÂ§öÈÉ®ÁæéÂõΩÁßëÂπªÁîµÂΩ±ÈôÜÁª≠‰∏äÊò†Â∞Ü‰∏∫ÂõΩÂÜÖÁîµÂΩ±Á•®ÊàøÂ∏ÇÂú∫ÂΩ¢ÊàêÊúâÂäõÁöÑÊîØÊíëÔºõÂêåÊó∂ 2019 Âπ¥Êò•ËäÇÊ°£ÁöÑ‰ºóÂ§öÂõΩ‰∫ßË¥∫Â≤ÅÁîµÂΩ±ÔºàÂ¶ÇÊµÅÊµ™Âú∞ÁêÉÁ≠âÔºâ‰πüÂÖ∑Â§áÂæàÂº∫ÁöÑÁ´û‰∫âÂäõÔºåÂõ†Ê≠§Êï¥‰Ωì‰∏äÊàë‰ª¨ËÆ§‰∏∫ 2019 Âπ¥ÂõΩÂÜÖÁîµÂΩ±Á•®ÊàøÂ∏ÇÂú∫Â∞ÜÁªßÁª≠‰øùÊåÅÂπ≥Á®≥Â¢ûÈÄüÊ∞¥Âπ≥ÔºåÂ¢ûÈÄüÁõ∏ËæÉ‰∫é 2018 Âπ¥Â∞ÜÊúâÊâÄÊèêÈ´òÔºå Èô¢Á∫øÂíåÁõ∏ÂÖ≥ÁàÜÊ¨æÂΩ±ÁâáÁöÑÂà∂Áâá/ÂèëË°åÊñπÂ∞ÜÊõ¥Âä†ÂèóÁõä„ÄÇ

  - **Answer:** 

    >Âº∫ÁÉàÊé®ËçêÔºÅ
    >Èâ¥‰∫éÂÖ¨Âè∏Âú®ÂèëË°å„ÄÅÊîæÊò†È¢ÜÂüüÂùáÊúâËæÉÂº∫ÂÆûÂäõ, ‰∏îÂØπ‰∏ä‰∏ãÊ∏∏‰∫ß‰∏öÂùáÊúâ‰∏ÄÂÆöÁöÑËØùËØ≠ÊùÉ, Êú™Êù•ÊúâÊúõÊåÅÁª≠‰∫´ÂèóÈ´òÊØõÂà©Ê∞¥Âπ≥ÁöÑ‰ºòË¥®ÂÜÖÂÆπ‰∫ßÂá∫Â∏¶Êù•ÁöÑÁ∫¢Âà©„ÄÇÂÖ∂Âº∫Â§ßÁöÑÂá∫ÂìÅËÉΩÂäõÂíå‰∏∞ÂØåÁöÑËµÑÊ∫êÁßØÁ¥Ø‰∏∫ÂÖ∂Êèê‰æõ‰∫ÜËâØÂ•ΩÁöÑÂàõ‰ΩúÂü∫Á°Ä, Âπ∂Âá≠ÂÄü‰ºòÁßÄÁöÑÊ∏†ÈÅìÊääÊéßÂäõËé∑ÂæóÊõ¥Â§ö‰ºòË¥®ÂÜÖÂÆπÁöÑ‰æõÂ∫î„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ã, ËÄÉËôëÂà∞‰∏öÁª©ÂºπÊÄßÁ©∫Èó¥Â§ßÔºàÂ¶Ç„ÄäÊµÅÊµ™Âú∞ÁêÉ„ÄãÁ≠âÔºâÁ≠âÂõ†Á¥†, ÊàëÂùö‰ø°ËØ•ÂÖ¨Âè∏Êú™Êù•ÁöÑÂâçÊôØÂÄºÂæóÊúüÂæÖ„ÄÇÂΩìÁÑ∂, ÊäïËµÑÁöÑÊΩúÂú®È£éÈô©‰ªçÈúÄÂÖ≥Ê≥®ÁõëÁÆ°ÊîøÁ≠ñÂíåÁñ´ÊÉÖÊÉÖÂÜµÁöÑÂèòÂåñ„ÄÇ‰ª•‰∏ä‰ªÖÊòØÂü∫‰∫éÂΩìÂâç‰ø°ÊÅØÁöÑÊé®ÁêÜÈ¢ÑÊµã, ÊäïËµÑÊúâÈ£éÈô©, ÂÜ≥Á≠ñÈúÄË∞®ÊÖé„ÄÇ

- **Event:**

  - **Question:** 

    >Áé∞Âú®‰Ω†‰ºöË¢´Êèê‰æõ‰∏Ä‰ªΩ‰∏≠ÂõΩÁöÑÊñ∞ÈóªÔºöÁªôÂÆöÊñ∞ÈóªÁöÑ‰∏ÄÁ∫ßÂàÜÁ±ªÔºåËØ∑Âú®ÊàëÁªôÂÆöÁöÑ‰∫åÁ∫ßÊ†áÈ¢ò‰∏≠ËøõË°åÈÄâÊã©„ÄÇ‰∏ÄÁ∫ßÂàÜÁ±ª‰∏∫ÔºöÈáëËûçÂ∏ÇÂú∫„ÄÇÂèØÈÄâÁöÑ‰∫åÁ∫ßÂàÜÁ±ª‰∏∫ÔºàÈáëËûçÂ∏ÇÂú∫, Ë°çÁîüÂìÅÂ∏ÇÂú∫, ÊúüË¥ßÂ∏ÇÂú∫, Ë¥µÈáëÂ±û, ËÇ°Á•®Â∏ÇÂú∫, AËÇ°, Ê∏ØËÇ°, ÊàøÂú∞‰∫ß, ÂÄ∫Âà∏Â∏ÇÂú∫, Êñ∞‰∏âÊùø‰∫§Êòì, Êµ∑Â§ñËÇ°Á•®Â∏ÇÂú∫, Â§ñÊ±áÂ∏ÇÂú∫, ‰∫∫Ê∞ëÂ∏ÅÊ±áÁéá, ÁæéÂÖÉÊ±áÁéá, ÂõΩÈôÖÈáëËûçÂ∏ÇÂú∫, Ê¨ßÂÖÉÊ±áÁéá, Èì∂Ë°åË¥∑Ê¨æ, ËÇ°ÊùÉÊäïËµÑ, Êó•ÂÖÉÊ±áÁéá, ETF, ÂÖ∂‰ªñÊ±áÁéá, ‰øùÈô©Â∏ÇÂú∫, ËôöÊãüË¥ßÂ∏Å, ÊúüÊùÉÂ∏ÇÂú∫, ËµÑ‰∫ßËØÅÂà∏ÂåñÂ∏ÇÂú∫, Âè¶Á±ªÂ∏ÇÂú∫Ôºâ„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºöÊ∏ØËµÑ8Êúà17Êó•ÔºåÂáÄ‰π∞ÂÖ•58.86‰∏áËÇ°ÔºåÁ∫¶335‰∏áÂÖÉÔºåÂ¢ûÊåÅÊØî‰æãÔºö0.11%ÔºåÊàê‰∫§Âç†ÊØîÔºö7.591%ÔºåÊåÅËÇ°ÊØî‰æãÔºö0.478%ÔºåËøûÁª≠8‰∏™‰∫§ÊòìÊó•Â¢ûÊåÅÔºåËøë5‰∏™‰∫§ÊòìÊó•ÊØî‰æãÂèòÂåñÔºö118.91%ÔºåËøë22‰∏™‰∫§ÊòìÊó•ÊØî‰æãÂèòÂåñÔºö383.418%ÔºåËøë66‰∏™‰∫§ÊòìÊó•ÊØî‰æãÂèòÂåñÔºö292.207%„ÄÇ

  - **Answer:** 

    >ÈáëËûçÂ∏ÇÂú∫, ËÇ°Á•®Â∏ÇÂú∫, AËÇ°

- **Industry:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏ÄÂêçÈáëËûçË°å‰∏öÁöÑ‰∏ìÂÆ∂ÔºåÁªôÂÆöÊñ∞ÈóªÁöÑ‰∏ÄÁ∫ßË°å‰∏öÔºåËØ∑Âú®ÊàëÁªôÂÆöÁöÑË°å‰∏ö‰∫åÁ∫ßÊ†áÈ¢ò‰∏≠ËøõË°åÈÄâÊã©„ÄÇ‰∏ÄÁ∫ßÂàÜÁ±ª‰∏∫ÔºöÁîµÊ∞îËÆæÂ§á„ÄÇÂèØÈÄâÁöÑ‰∫åÁ∫ßÂàÜÁ±ª‰∏∫ÔºàÁîµÊ∫êËÆæÂ§á, È´ò‰ΩéÂéãËÆæÂ§á, ÁîµÊ∞îËá™Âä®ÂåñËÆæÂ§á, ÁîµÊú∫Ôºâ„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºö    12Êúà31Êó•ÔºåËµÑÊú¨ÈÇ¶Ëé∑ÊÇâÔºåÊ∏ØËÇ°‰∏äÂ∏ÇÂÖ¨Âè∏Á¶èËé±ÁâπÁéªÁíÉ(06865.HK)‰∫é12Êúà30Êó•ÂèëÂ∏ÉÂÖ¨ÂëäÁß∞ÔºåÁ¶èËé±ÁâπÁéªÁíÉÂèäÂÖ∂ÂÖ®ËµÑÈôÑÂ±ûÂÖ¨Âè∏(‰∏ãÊñáÁÆÄÁß∞‚ÄúÂçñÊñπ)Â∑≤‰∏éÊô∂ÁßëÈõÜÂõ¢ÂèäÂÖ∂ÂÖ®ËµÑÈôÑÂ±ûÂÖ¨Âè∏(‰∏ãÊñáÁÆÄÁß∞‚Äú‰π∞Êñπ‚Äù)ÂÖ≥‰∫éÈîÄÂîÆÂÖâ‰ºèÂéãÂª∂ÁéªÁíÉ‰∫ãÈ°πÁ≠æËÆ¢„ÄäÊàòÁï•Âêà‰ΩúÂçèËÆÆ„Äã„ÄÇÊ†πÊçÆÂçèËÆÆÔºå‰π∞ÊñπÂú®2021~2023Âπ¥‰∏âÂπ¥ÂÜÖÂêëÂçñÊñπÈááË¥≠ÂÖ±ËÆ°59GW(Á∫¶3.38‰∫øÂπ≥ÊñπÁ±≥)ÁªÑ‰ª∂Áî®ÂÖâ‰ºèÂéãÂª∂ÁéªÁíÉÔºåÂêàÂêåÂ±•Ë°åÊúüÈôêËá™2021Âπ¥1Êúà1Êó•Ëµ∑Ëá≥2023Âπ¥12Êúà31Êó•Ê≠¢„ÄÇÊåâÁÖßÂçìÂàõÂë®Êä•2020Âπ¥12Êúà24Êó•ÂÖ¨Â∏ÉÁöÑÂÖâ‰ºèÁéªÁíÉÂùá‰ª∑42ÂÖÉ/Âπ≥Êñπ(Âê´Á®é)ÊµãÁÆóÔºåÈ¢Ñ‰º∞ÂêàÂêåÊÄªÈáëÈ¢ùÁ∫¶141.96‰∫øÂÖÉ‰∫∫Ê∞ëÂ∏Å(Âê´Á®é)„ÄÇ
    >Á¶èËé±ÁâπÁéªÁíÉËÆ§‰∏∫ÔºåÊ≠§Ê¨°ÂçèËÆÆÁöÑÁ≠æËÆ¢ÊúâÂà©‰∫éÂÖ¨Âè∏ÂÖâ‰ºèÂéãÂª∂ÁéªÁíÉ‰∫ßÂìÅÁöÑÂ∏ÇÂú∫Êé®Âπø‰ª•ÂèäËøõ‰∏ÄÊ≠•ÊèêÂçáÂÖ¨Âè∏ÁªèËê•‰∏öÁª©„ÄÇ
    >ÊçÆÊÇâÔºåÁ¶èËé±ÁâπÁéªÁíÉÊòØ‰∏ÄÂÆ∂ÈõÜÁéªÁíÉÁ†îÂèë„ÄÅÂà∂ÈÄ†„ÄÅÂä†Â∑•ÂíåÈîÄÂîÆ‰∏∫‰∏Ä‰ΩìÁöÑÁªºÂêàÊÄß‰∏≠Â§ßÂûã‰ºÅ‰∏öÔºåÂàõÂª∫‰∫é1998Âπ¥6ÊúàÔºåÈõÜÂõ¢Êú¨ÈÉ®‰Ωç‰∫éÈïø‰∏âËßíÁªèÊµé‰∏≠ÂøÉÊµôÊ±üÂòâÂÖ¥Â∏Ç„ÄÇÁ¶èËé±ÁâπÁéªÁíÉÁöÑ‰∏ªË¶Å‰∫ßÂìÅÊ∂âÂèäÂ§™Èò≥ËÉΩÂÖâ‰ºèÁéªÁíÉ„ÄÅ‰ºòË¥®ÊµÆÊ≥ïÁéªÁíÉ„ÄÅÂ∑•Á®ãÁéªÁíÉ„ÄÅÂÆ∂Â±ÖÁéªÁíÉÂõõÂ§ßÈ¢ÜÂüüÔºå‰ª•ÂèäÂ§™Èò≥ËÉΩÂÖâ‰ºèÁîµÁ´ôÁöÑÂª∫ËÆæÂíåÁü≥Ëã±Â≤©ÁüøÂºÄÈááÔºåÂΩ¢Êàê‰∫ÜÊØîËæÉÂÆåÊï¥ÁöÑ‰∫ß‰∏öÈìæ„ÄÇ

  - **Answer:** 

    >ÁîµÊ∫êËÆæÂ§á, È´ò‰ΩéÂéãËÆæÂ§á


- **Company:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏ÄÂêçÂÖ∑Êúâ‰∏∞ÂØåÊäïÈ°æÁªèÈ™åÁöÑÈáëËûçÁ†îÁ©∂ÂëòÔºåÁé∞Âú®ÈúÄË¶Å‰Ω†‰∏éÈáëËûçÂ∏ÇÂú∫Áõ∏ÂÖ≥ÁöÑÊñ∞ÈóªÂÜÖÂÆπËøõË°åÂàÜÊûê„ÄÇÈúÄÊ±ÇÔºö‰Ω†ËÉΩÂ∏ÆÊàëÊÄªÁªìÂá∫ËØ•Êñ∞Èóª‰∏≠Ê∂âÂèäÁöÑÂÖ¨Âè∏ÂêçÁß∞ÂêóÔºüÊñ∞ÈóªÂÜÖÂÆπÔºö    Ê¥ãÊ≤≥ÂèëÂ∏ÉÊ†∏ÂøÉÈ™®Âπ≤ÊåÅËÇ°ËÆ°ÂàíÔºåÊéà‰∫àÂØπË±°‰∏ªË¶ÅÂåÖÊã¨ÂÖ¨Âè∏È´òÁÆ°ÔºåÊ†∏ÂøÉ‰∏≠Â±ÇÂèä‰∏öÂä°È™®Âπ≤ÔºåËÄÉÊ†∏ÁõÆÊ†á‰∏∫21,22Âπ¥Ëê•‰∏öÊî∂ÂÖ•Áõ∏ÊØî‰∫é‰∏ä‰∏ÄÂπ¥Ëê•‰∏öÊî∂ÂÖ•Â¢ûÈÄüË∂ÖËøá15%„ÄÇÊàë‰ª¨ËÆ§‰∏∫Âú®Ê¨°È´òÁ´ØË°å‰∏öÊ∂àË¥πÂçáÁ∫ß‰ª•ÂèäÂÖ¨Âè∏ÂéªÂ∫ìÂ≠òÊé®Âä®Ê∏†ÈÅìÂà©Ê∂¶ÊèêÂçáÁöÑÂü∫Á°Ä‰∏ãÔºåÂÖ¨Âè∏ÂÆûÁé∞‰ªªÂä°ÁõÆÊ†áÁöÑÊ¶ÇÁéáËæÉÈ´ò„ÄÇÁï•Ë∞ÉÊï¥21-23Âπ¥EPS‰∏∫5.57„ÄÅ6.76„ÄÅ8.23.Áª¥ÊåÅ22Âπ¥37xÔºå‰∏ÄÂπ¥ÁõÆÊ†á‰ª∑250ÂÖÉÔºåÁª¥ÊåÅ‚ÄúÂº∫ÁÉàÊé®Ëçê-A‚ÄùËØÑÁ∫ß„ÄÇÊé®ËçêÈòÖËØªÊàë‰ª¨ÁöÑÊ∑±Â∫¶Êä•Âëä„ÄäÊ¥ãÊ≤≥Ê∑±Â∫¶ÔºöÊîπÈù©‰πãË∑Ø„Äã
    >Ê¥ãÊ≤≥ËÇ°‰ªΩÂèëÂ∏ÉÊåÅËÇ°ËÆ°ÂàíÔºå‰∏öÁª©Á°ÆÂÆöÊÄßËøõ‰∏ÄÊ≠•ÊèêÂçá„ÄÇÊ¥ãÊ≤≥ËÇ°‰ªΩÂèëÂ∏ÉÁ¨¨‰∏ÄÊúüÊ†∏ÂøÉÈ™®Âπ≤ÊåÅËÇ°ËÆ°ÂàíÔºåÊéà‰∫àÂØπË±°‰∏ªË¶ÅÂåÖÊã¨ÂÖ¨Âè∏È´òÁÆ°‰ª•ÂèäÂÖ¨Âè∏ÂèäÂÖ®ËµÑÂ≠êÂÖ¨Âè∏ÁöÑÊ†∏ÂøÉ‰∏≠Â±ÇÂèä‰∏öÂä°È™®Âπ≤„ÄÇÊåÅËÇ°ËÆ°ÂàíÂØπÂ∫î21,22Âπ¥‰∏öÁª©ËÄÉÊ†∏ÊåáÊ†á‰∏∫Ëê•‰∏öÊî∂ÂÖ•Áõ∏ÊØî‰∫é‰∏ä‰∏ÄÂπ¥Ëê•‰∏öÊî∂ÂÖ•Â¢ûÈÄüË∂ÖËøá15%„ÄÇÊú¨ËΩÆËÇ°ÊùÉÊøÄÂä±ÊÄªÈáëÈ¢ù‰∏∫10.03‰∫øÂÖÉÔºåÂØπÂ∫îËÇ°Êú¨9,661,310ËÇ°ÔºåÂç†ÂÖ¨Âè∏ÊÄªËÇ°Êú¨ÁöÑ0.64%ÔºåÂØπÂ∫îÂΩìÂâçËÇ°Á•®Â∏ÇÂÄº18.9‰∫øÂÖÉ„ÄÇÊéà‰∫à‰ª∑Ê†º‰∏∫ÂÖ¨Âè∏‰πãÂâçÂõûË¥≠ÊàêÊú¨,Âç≥103.73ÂÖÉ/ËÇ°„ÄÇ
    >‰ΩéÂ∫ìÂ≠òÂíåÊ∏†ÈÅìÂà©Ê∂¶ÊîØÊíë‰∏ãÔºåÊàë‰ª¨Âà§Êñ≠ÂÖ¨Âè∏ÊúâÊúõÈ°∫Âà©ÂÆåÊàêÁõÆÊ†á„ÄÇ‰ªäÂπ¥‰ª•Êù•Ê¥ãÊ≤≥ÊåÅÁª≠ÂéªÂ∫ìÂ≠òÔºåÁõÆÂâçÊ∏†ÈÅìÂ∫ìÂ≠òÂ§Ñ‰∫éÂéÜÂè≤‰Ωé‰ΩçÔºå‰∏äÂçäÂπ¥ÁªàÁ´ØÂä®ÈîÄÂ¢ûÈÄüË∂ÖËøá20%„ÄÇÊàë‰ª¨ËÆ§‰∏∫Âú®Ê¨°È´òÁ´ØÁôΩÈÖíË°å‰∏öÊ∂àË¥πÊåÅÁª≠ÂçáÁ∫ß‰ª•ÂèäÂÖ¨Âè∏ÂéªÂ∫ìÂ≠òÊé®Âä®Ê∏†ÈÅì‰ª∑ÂÄºÈìæ‰∏çÊñ≠ÊèêÂçáÁöÑÂü∫Á°Ä‰∏ãÔºåÂÖ¨Âè∏È°∫Âà©ÂÆûÁé∞‰ªªÂä°ÁõÆÊ†áÁöÑÊ¶ÇÁéáËæÉÈ´ò„ÄÇ
    >Êú¨ËΩÆËÇ°ÊùÉÊøÄÂä±Ë¶ÜÁõñÈù¢ÂπøÔºåÊèêÂçáÊï¥‰ΩìÁöÑÂëòÂ∑•ÁßØÊûÅÊÄß„ÄÇÊú¨ËΩÆÊîπÈù©‰πãÂâçÔºåÊ¥ãÊ≤≥ÁöÑËÇ°ÊùÉÊøÄÂä±ÂØπË±°‰∏ªË¶ÅÈõÜ‰∏≠Âú®‰πãÂâçÁöÑÁÆ°ÁêÜÂ±ÇÔºåÁé∞‰ªªÁÆ°ÁêÜÂ±ÇÁº∫‰πèËÇ°ÊùÉÊøÄÂä±Êàñ‰ΩìÈáèÁõ∏ÂØπËæÉÂ∞è„ÄÇÂêåÊó∂Êú¨ËΩÆËÇ°ÊùÉÊøÄÂä±ËÆ°Âàí‰∏≠ÔºåÊ†∏ÂøÉÈ™®Âπ≤Âç†ÊØî91.72%ÔºåË¶ÜÁõñ‰∫ÜÂÖ¨Âè∏Ê†∏ÂøÉ‰∏≠Â±ÇÂèä‰∏öÂä°È™®Âπ≤„ÄÇÈïøÊúü‰ª•Êù•Ê¥ãÊ≤≥‰æùÊâò‰∫éÊ∏†ÈÅìÁöÑÂº∫ÊéßÂà∂Âäõ‰ª•ÂèäÂú®ÂìÅÁâåÔºå‰∫ßÂìÅ‰∏äÁöÑ‰∏çÊñ≠ÂàõÊñ∞ÔºåÊåÅÁª≠ÊèêÂçáÂÖ¨Âè∏ÁöÑÁªºÂêàÁ´û‰∫âÂäõ„ÄÇÊàë‰ª¨ËÆ§‰∏∫Êú¨ËΩÆËÇ°ÊùÉÊøÄÂä±ÊñπÊ°àÊúâÂä©‰∫éÂº∫ÂåñÂÖ¨Âè∏ÁöÑÊ∏†ÈÅìÊéßÂà∂Âäõ‰ª•ÂèäÊèêÂçáÂÖ¨Âè∏‰∏öÂä°ÂàõÊñ∞Ê¥ªÂäõÔºåÊåÅÁª≠ÊèêÂçáÂÖ¨Âè∏ÁöÑÈïøÊúüÁ´û‰∫âÂäõ„ÄÇ
    >ÂÖ¨Âè∏‰∫ßÂìÅÊîπÈù©ÊåÅÁª≠Êé®ËøõÔºå‰∫ßÂìÅÂä®ÈîÄÊåÅÁª≠Âä†ÈÄü„ÄÇÊàë‰ª¨ÂâçÊúüË∞ÉÁ†îÊòæÁ§∫ÔºåÂÖ¨Âè∏ÁúÅÂÜÖÂ∏ÇÂú∫ËÄÅÁâàÂ§©‰πãËìùÂ∫ìÂ≠òÂ∑≤ÁªèÂü∫Êú¨Ê∂àÂåñÂπ≤ÂáÄÔºåÁúÅÂ§ñÈÉ®ÂàÜÂ∏ÇÂú∫Â§©‰πãËìù‰ªçÊúâÂ∞ëÈáèÂ∫ìÂ≠òÔºå‰∏∫‰∫ßÂìÅÊç¢‰ª£Â∑≤ÁªèÂÅöÂ•Ω‰∫ÜÂáÜÂ§á„ÄÇÊ¢¶‰πãËìùÊ∞¥Êô∂ÁâàÈì∫Ë¥ßÊåÅÁª≠Êé®ËøõÔºåÁúÅÂÜÖÁªèÈîÄÂïÜÈ¢ÑËÆ°‰ªäÂπ¥‰∏≠ÁßãÂõΩÂ∫ÜÊúüÈó¥Â∞ÜËøéÊù•ÊîæÈáèÔºåÁõÆÂâçÊï¥‰ΩìÁöÑÂ∫ìÂ≠òÊ∞¥Âπ≥Áõ∏ÊØî‰∫éÂπ¥ÂàùÂ∑≤ÁªèÊúâÊòéÊòæ‰∏ãÈôçÔºåÊï¥‰ΩìÂ§Ñ‰∫éÂêàÁêÜÂå∫Èó¥ÂÜÖ„ÄÇËçâÊ†πË∞ÉÁ†îÊòæÁ§∫ÔºåM6+Êâπ‰ª∑ÊåÅÁª≠Áª¥ÊåÅÂú®620ÂÖÉ‰ª•‰∏äÔºåÊ∏†ÈÅìÂà©Ê∂¶Áª¥ÊåÅÂú®12%‰ª•‰∏äÔºåÁªèÈîÄÂïÜÈîÄÂîÆÁßØÊûÅÊÄßÈ´òÔºåÊ∏†ÈÅìÂ∫ìÂ≠òÁ¥ßÂº†„ÄÇ
    >ÊäïËµÑÂª∫ËÆÆÔºöÊ¥ãÊ≤≥È´ò‰ª∑‰ΩçÊÆµÊ¨°È´òÁ´ØÁöÑÈ¢ÜÂÖàÂ∏ÉÂ±Ä‰∏éÊ∏†ÈÅìÂéªÂ∫ìÂ≠òÂêéÊåÅÁª≠ÊîπÂñÑÂ∞ÜÊãâÂä®ÂÖ¨Âè∏ÁöÑÊàêÈïøÔºåÁª¥ÊåÅ‚ÄúÂº∫ÁÉàÊé®Ëçê-A‚ÄùËØÑÁ∫ß„ÄÇÊ¥ãÊ≤≥Âú®600-800ÂÖÉ‰ª∑Ê†ºÂ∏¶Â∏ÉÂ±ÄÈ¢ÜÂÖàÂ§ßÈÉ®ÂàÜÁ´û‰∫âÂØπÊâãÔºåÊ¢¶6+‰ΩìÈáèÂú®Ë°å‰∏öÂÜÖÂÖ∑Â§áÊòæËëó‰ºòÂäøÔºåÊú™Êù•Â∞ÜÁéáÂÖàÊä¢Âç†ËØ•‰ª∑Ê†ºÂ∏¶ÁöÑÊàòÁï•ÂèëÂ±ïÊú∫‰ºö„ÄÇÁõÆÂâçÊù•ÁúãÂÖ¨Âè∏ÁúÅÂÜÖÂ§ñÊ∏†ÈÅìÊ¢≥ÁêÜËæÉ‰∏∫È°∫ÁïÖÔºåÊ∏†ÈÅìÂà©Ê∂¶ÂæóÂà∞ÊòæËëóÊÅ¢Â§çÔºåÂÖ¨Âè∏2021Âπ¥Â∞ÜÂÆåÊàêÊ∞¥Êô∂Ê¢¶ÁöÑÊç¢‰ª£‰ª•ÂèäÊñ∞ÁâàÂ§©‰πãËìùÁöÑÊé®Âá∫ÔºåÊúâÊúõÂú®2022Âπ¥Ëøõ‰∏ÄÊ≠•Âä©Êé®ÂÖ¨Âè∏ÁöÑÊàêÈïø„ÄÇÁï•Ë∞ÉÊï¥21-23Âπ¥EPS‰∏∫5.57„ÄÅ6.76„ÄÅ8.23.Áª¥ÊåÅ22Âπ¥37xÔºå‰∏ÄÂπ¥ÁõÆÊ†á‰ª∑250ÂÖÉÔºåÁª¥ÊåÅ‚ÄúÂº∫ÁÉàÊé®Ëçê-A‚ÄùËØÑÁ∫ß„ÄÇ
    >È£éÈô©ÊèêÁ§∫ÔºöË°å‰∏öÈúÄÊ±ÇÂõûËêΩÔºåÁúÅÂÜÖÁ´û‰∫âÂä†ÂâßÔºåÁúÅÂ§ñÊãìÂ±ï‰∏çÂèäÈ¢ÑÊúü„ÄÇ

  - **Answer:** 

    >Ê¥ãÊ≤≥ËÇ°‰ªΩ

- **Product:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏ÄÂêçÂÖ≥Ê≥®ÈáëËûçÂ∏ÇÂú∫ÁöÑÊäïËµÑËÄÖÔºåËØ∑ÂàÜÊûêËøôÁØáÊñ∞Èóª„ÄÇÈ∫ªÁÉ¶ÊÇ®ÊâæÂá∫ËØ•Êñ∞Èóª‰∏≠Ê∂âÂèäÂà∞ÁöÑÁõ∏ÂÖ≥‰∫ßÂìÅ„ÄÇÊñ∞ÈóªÂÜÖÂÆπÔºö    ÊñπÊ≠£‰∏≠ÊúüÁ†îÁ©∂Âëò Âè≤ÂÆ∂‰∫Æ„ÄêË°åÊÉÖÂ§çÁõò„ÄëËôΩÁÑ∂ÊúâËâ≤ÊùøÂùóÂÅèÂº±ÔºåÁÑ∂Ê≤™Èî°Âú®Áé∞Ë¥ßÁ¥ßÁº∫Âõ†Á¥†Êé®Âä®‰∏ãÈÄÜÂäø‰∏äÊ∂®ÔºåË°®Áé∞‰∏ÄÊûùÁã¨ÁßÄÔºåÁªßÁª≠Â§ßÊ∂®Ôºå09ÂêàÁ∫¶Â∞æÁõòÊ∂®2.71%Ëá≥23.67‰∏áÂÖÉÔºåÁªìÁÆó‰ª∑‰∏∫23.29‰∏áÂÖÉ„ÄÇÂΩìÂâçÔºåÈî°Áé∞Ë¥ßÁ´ØÁº∫Ë¥ß‰æùÊóßÔºåÂΩìÂâç‰∏äÊúüÊâÄ‰ªìÂçïÁîöËá≥Èöæ‰ª•Ë¶ÜÁõñ08ÂêàÁ∫¶ÂæÖ‰∫§Ââ≤ÈáèÔºåÂπ∂‰∏î‰∫ëÈî°Â∑≤ÁªèÂ§ç‰∫ß‰∫Ü‰πüÊ≤°ËÉΩÁºìËß£Áé∞Ë¥ßÁ¥ßÁº∫ÁöÑÁé∞Áä∂ÔºåÊâÄ‰ª•Âº∫‰æõÈúÄÊîØÊíë‰∏ãÈî°‰ª∑Âº∫ÂäøË°åÊÉÖ‰æùÊóß„ÄÇ‰º¶Èî°ÊñπÈù¢ÔºåÊà™Ê≠¢17Ôºö00ÔºåLME‰∏â‰∏™ÊúàÊúüÈî°Áé∞Êä•35165ÁæéÂÖÉ/Âê®ÔºåÂàõÂéÜÂè≤Êñ∞È´òÔºåÊï¥‰ΩìÂº∫ÂäøË°åÊÉÖ‰ªçÂú®ÊåÅÁª≠ÔºåÂØπÊ≤™Èî°ÁöÑÊúâÊïàÊîØÊíë‰æùÁÑ∂Â≠òÂú®„ÄÇÁªºÂêàËÄÉËôëÊ±áÁéá„ÄÅÂ¢ûÂÄºÁ®éÁéáÂíåÊ∏ØÊùÇË¥πÁ≠âÂõ†Á¥†ÔºàÊ†πÊçÆ‰∫ÜËß£ÔºåÊöÇÊó∂Êó†8%ÁöÑÂÖ≥Á®éÔºâÔºåÂØπÈî°‰ª∑ÂÜÖÂ§ñÁõò‰ª∑Ê†ºËøõË°åÊµãÁÆóÔºå3.45‰∏áÁöÑ‰º¶Èî°ÂØπÂ∫îÁöÑÂà∞Â≤∏‰ª∑Ê†º‰∏∫25.34‰∏áÂÖÉÔºå3.5‰∏áÁöÑ‰º¶Èî°ÂØπÂ∫îÁöÑÂà∞Â≤∏‰ª∑Ê†º‰∏∫26.44‰∏áÂÖÉÔºõÂç≥‰ΩøÂä†ÂÖ•ËøêË¥πÁöÑËÄÉÈáèÔºå‰º¶Èî°‰ª∑Ê†º‰æùÁÑ∂È´ò‰∫éÊ≤™Èî°‰ª∑Ê†º„ÄÇ
    >ÈáçË¶ÅËµÑËÆØ„ÄëÂü∫Êú¨Èù¢ÊñπÈù¢‰æùÁÑ∂Âà©Â•ΩÈî°‰ª∑ÔºöÂ∫ìÂ≠òÊñπÈù¢Ôºå‰∏äÊúüÊâÄÊåáÂÆö‰∫§Ââ≤‰ªìÂ∫ì‰ªìÂçïÁªßÁª≠‰∏ãË∑å56Âê®Ëá≥1514Âê®ÔºåÊï¥‰ΩìÂéªÂ∫ìË∂ãÂäø‰æùÊóßÔºåÂπ∂‰∏îÁé∞Ë¥ßÁ´Ø‰æùÁÑ∂ÂÅèÁ¥ßÔºåÊ∂àË¥πÊó∫Â≠£ÂéªÂ∫ìË∂ãÂäø‰ªçÂ∞Ü‰ºöÊåÅÁª≠Ôºõ‰º¶Èî°Â∫ìÂ≠òÊñπÈù¢Ôºå‰º¶Èî°Â∫ìÂ≠òÁª¥ÊåÅÂú®2245Âê®Â∑¶Âè≥ÔºåÂΩìÂâçÂ∫ìÂ≠ò‰æùÁÑ∂Â§Ñ‰∫é‰Ωé‰Ωç„ÄÇÈî°Èî≠‰∫ßÈáèÊñπÈù¢ÔºåÂèó‰∫ëÈî°ÂÜ∂ÁÇºÁ≥ªÁªüÂçáÁ∫ßÊîπÈÄ†‰ª•ÂèäÂçéÈî°ÂèóÂΩìÂú∞ÈôêÁîµÊîøÁ≠ñÂΩ±ÂìçÔºåÂÜÖËíô„ÄÅ‰∫ëÂçóÂú∞Âå∫ÈÉ®ÂàÜ‰ºÅ‰∏ö‰ªçÂõ†ÂéüÊñôÁü≠Áº∫ÂèäÂä†Â∑•Ë¥π‰ΩéËø∑ÈóÆÈ¢òÁª¥ÊåÅ‰ΩéÈáèÁîü‰∫ßÔºå7ÊúàÂõΩÂÜÖÁ≤æÈî°ÊÄª‰∫ßÈáè‰∏ãÈôçÊòéÊòæÔºåÂêéÂ∏ÇËøõÂè£ÂíåÂõΩÂÜÖÂéüÊùêÊñôÁöÑ‰æõÂ∫î‰æùÁÑ∂‰ºöÂÅèÁ¥ß„ÄÇÂèóÈî°Èî≠Âá∫Âè£‰∏ãÈôçÂΩ±ÂìçÔºåÈî°Èî≠Ë°®ËßÇÊ∂àË¥πÈáè‰Ωé‰ΩçÂõûÂçáÔºõÂπ∂‰∏î6ÊúàÈî°Á≤æÁüøËøõÂè£Âá∫Áé∞Â§ßÂπÖÂõûÂçá‰∫¶‰ΩøÂæóÈî°Á≤æÁüøË°®ËßÇÊ∂àË¥πÈáèÂá∫Áé∞Â§ßÂπÖÂõûÂçáÔºåÊî∂Â§ç5ÊúàË∑åÂπÖÔºõÁÑ∂ËÄåÂç≥‰ΩøÂ¶ÇÊ≠§ÔºåÂõΩÂÜÖÈî°Áé∞Ë¥ßÂ∏ÇÂú∫Ë¥ßÊ∫ê‰æùÁÑ∂Á¥ßÂº†ÔºåÈî°Èî≠ÈááË¥≠ÈöæÂ∫¶ËæÉÂ§ßÔºåËØ¥ÊòéÈî°Èî≠ÁöÑÈúÄÊ±Ç‰∫¶ÊòØÂº∫Âä≤ÔºåËøôÂùáÊîØÊíë‰∫ÜÈî°‰ª∑„ÄÇ‰∫ëÈî°Â∑≤ÁªèÂ§ç‰∫ßÔºå‰ΩÜÊòØ‰æùÁÑ∂Ê≤°ÊúâÁºìËß£Èî°Áé∞Ë¥ßÁöÑÁ¥ßÁº∫Á®ãÂ∫¶„ÄÇ
    >„Äê‰∫§ÊòìÁ≠ñÁï•„ÄëÂü∫Êú¨Èù¢ÂíåÂ§ñÁõòË°®Áé∞ÁªßÁª≠ÊîØÊíëÁùÄÂÜÖÁõòÈî°‰ª∑ÔºåÊ≤™Èî°ÂéªÂ∫ìË∂ãÂäøÊåÅÁª≠ÔºåÊïÖÊ≤™Èî°‰æõÈúÄÂü∫Êú¨Èù¢‰æùÁÑ∂ËæÉÂº∫ÔºåÁâπÂà´ÊòØÁé∞Ë¥ßÁ´ØÁ¥ßÁº∫‰æùÊóßÔºåÈî°ÁöÑÊï¥‰ΩìÂº∫ÂäøË°åÊÉÖ‰ªçÂú®ÊåÅÁª≠„ÄÇÂΩìÂâçËøõÂÖ•È´ò‰ΩçÈúáËç°Ë°åÊÉÖÔºå‰ΩÜÊòØ‰æùÁÑ∂‰∏çÂª∫ËÆÆÂÅöÁ©∫ÔºåÁâπÂà´ÊòØ‰º¶Èî°‰æùÁÑ∂Âº∫‰∫éÊ≤™Èî°ÂíåÂü∫Êú¨Èù¢Ê≤°ÊúâÂèëÁîüÂèòÂåñËÉåÊôØ‰∏ãÔºå‰æùÁÑ∂Áª¥ÊåÅÈÄ¢‰ΩéÂÅöÂ§öÊÄùË∑ØÔºå‰∏äÊñπ‰ªçÊúâÂà∑Êñ∞ÂéÜÂè≤Êñ∞È´òÁöÑÂèØËÉΩÔºàÊ∂®Ëá≥24‰∏á‰∏äÊñπÂêéÔºå‰∏äÊé¢25‰∏áÈ´ò‰ΩçÁöÑÂèØËÉΩÊÄß‰ªçÂ≠òÔºâÔºåÁü≠ÊúüÂÜÖ‰∏ãÊñπÊîØÊíë‰Ωç‰∏∫22.6‰∏áÁöÑÂíå22.3‰∏áÁöÑÂâç‰Ωé‰ΩçÁΩÆÔºõÂõûË∞ÉÂàôÊòØÂÅöÂ§öÊú∫‰ºö„ÄÇ

  - **Answer:** 

    >Èî°, Ê≤™Èî°, ‰º¶Èî°, ‰∫ëÈî°

- **Exam:**

  - **Question:** 

    >ÂëΩÈ¢òÔºöÊåâÁÖßÂçï‰Ωç‰∏öÂä°Êï∞ÈáèÂà∂ÂÆö‰∏Ä‰∏™Âõ∫ÂÆö‰∏çÂèòÁöÑËµÑË¥πÊØîÁéáÔºåÊ†πÊçÆÁî®Êà∑‰ΩøÁî®ÁöÑÈÄö‰ø°‰∏öÂä°Êï∞ÈáèÁöÑÂ§öÂ∞ëÊî∂ÂèñÈÄö‰ø°Ë¥πÁî®ÁöÑ‰∏ÄÁßçËµÑË¥πÊ®°ÂºèÊòØÂÆöÈ¢ùËµÑË¥π„ÄÇ ÂàÜÊûêËß£ÈáäÔºöÊú¨È¢òËÄÉÊü•Á∫øÊÄßËµÑË¥π„ÄÇÁ∫øÊÄß‰ªéÈáèËµÑË¥πÊåáÁöÑÊòØÊåâÁÖßÂçï‰Ωç‰∏öÂä°Êï∞ÈáèÂà∂ÂÆö‰∏Ä‰∏™Âõ∫ÂÆö‰∏çÂèòÁöÑËµÑË¥πÊØîÁéáÔºåÊ†πÊçÆÁî®Êà∑‰ΩøÁî®ÁöÑÈÄö‰ø°‰∏öÂä°Êï∞ÈáèÁöÑÂ§öÂ∞ëÊî∂ÂèñÈÄö‰ø°Ë¥πÁî®ÁöÑ‰∏ÄÁßçËµÑË¥πÊ®°Âºè„ÄÇÊ†πÊçÆ‰ª•‰∏äÂàÜÊûêËß£ÈáäÔºå‰Ω†ËÆ§‰∏∫‰∏äËø∞ÂëΩÈ¢òÊòØÂê¶Ê≠£Á°ÆÔºü

  - **Answer:** 

    >ÈîôËØØ„ÄÇ

- **Stock:**

  - **Question:** 

    >‰Ω†ÊòØ‰∏Ä‰∏™ÈáèÂåñ‰∫§ÊòìÁ†îÁ©∂Âëò„ÄÇËØ∑‰Ω†Ê†πÊçÆÊèê‰æõÁöÑËÉåÊôØ‰ø°ÊÅØÔºåÊé®ÊµãË¥µÂ∑ûËåÖÂè∞Êú™Êù•‰∫îÂ§©ÁöÑËÇ°‰ª∑ÂèòÂåñË∂ãÂäø„ÄÇÂΩìÂâçË¥µÂ∑ûËåÖÂè∞ÁöÑÂâçÂçÅÂ§©ÁöÑÂéÜÂè≤Êî∂Áõò‰ª∑‰∏∫[1802.59, 1791.0, 1788.0, 1774.0, 1816.3, 1824.98, 1834.97, 1851.33, 1856.0, 1847.0,]„ÄÇÁõ∏ÂÖ≥ÁÉ≠ÁÇπÊñ∞Èóª‰ø°ÊÅØÔºöËøëÊúüË¥µÂ∑ûËåÖÂè∞‰∏éÁëûÂπ∏ÂíñÂï°Ë∑®ÁïåÂç≥Â∞ÜÊé®Âá∫ÁöÑËåÖÂè∞ÊãøÈìÅËøÖÈÄüÂá∫ÂúàÔºåÈ¢ÑËÆ°ÈîÄÈáèÁ™ÅÁ†¥ÂçïÊó•500‰∏á„ÄÇÁõ∏ÂÖ≥Á§æ‰∫§Â™í‰ΩìÁÉ≠ÁÇπËØÑËÆ∫ÔºöÁëûÂπ∏xËåÖÂè∞„ÄåÈÖ±È¶ôÊãøÈìÅ„ÄçÁàÜÁ∫¢Ôºõ8Êúà31Êó•Ê∂àÊÅØÔºåÊÉ≥ÂøÖÂæàÂ§ö80/90ÂêéÈÉΩÂê¨Ëøá„ÄäÁæéÈÖíÂä†ÂíñÂï°„ÄãËøôÈ¶ñËÄÅÊ≠åÔºåÊòØÁöÑÔºåÂÆÉÁúüÁöÑË¶ÅÊù•‰∫Ü„ÄÇËøëÊó•ÔºåÁΩë‰º†ËåÖÂè∞Â∞Ü‰∏éÁëûÂπ∏Â∞ÜÊé®Âá∫ËÅîÂêçÊ¨æÂíñÂï°ÔºåÁõÆÂâçÊùØÂ•ó„ÄÅÁ∫∏Ë¢ãÁöÑÂâßÈÄèÂõæÂ∑≤ÊµÅÂá∫ÔºåÊõùÂÖâÁöÑÊùØÂ•óÂíåÁ∫∏Ë¢ã‰∏äÈÉΩÊúâÈùûÂ∏∏ÊòéÊòæÁöÑËåÖÂè∞È£éÊ†ºÔºå‰∏äÈù¢ËøòÊ†áÊ≥®ÁùÄÔºö‚Äú‰∏≠ÂõΩ‰∫∫ÁöÑÁ¨¨‰∏ÄÊùØÈÖ±È¶ôÊãøÈìÅ‚ÄùÂíå‚ÄúÁæéÈÖíÂä†ÂíñÂï°ÔºåÂ∞±Áà±Ëøô‰∏ÄÊùØ‚ÄùÔºõÊçÆË¥¢ËÅîÁ§æÊä•ÈÅìÔºåÊúâÊé•ËøëËåÖÂè∞ÁöÑ‰∫∫Â£´ÈÄèÈú≤ÔºåÊ≠§Ê¨°ËÅîÂêçÂíñÂï°ÊòØÁü≠ÊúüÊÄßÁöÑÔºåËÄå‰∏îÊúâÈôêÈáè„ÄÇÊçÆÊ≠§ÂèØ‰ª•ÁåúÊµãÔºåËøôÊ¨æÊãøÈìÅÊÄïÊòØÂèàË¶ÅÂèóÂà∞Â∏ÇÂú∫ÁÉ≠ÁÇí‰∫Ü„ÄÇ 

  - **Answer:** 

    >Ê†πÊçÆÂéÜÂè≤ËÇ°‰ª∑„ÄÅÁÉ≠ÁÇπÊñ∞ÈóªÂíåÁ§æÂ™íËØÑËÆ∫ÔºåË¥µÂ∑ûËåÖÂè∞ÊúÄËøë‰∏éÁëûÂπ∏ÂíñÂï°Âêà‰ΩúÊé®Âá∫ËåÖÂè∞ÊãøÈìÅÔºåËøôÂ∞ÜÂØºËá¥ÈîÄÈáèÊÄ•ÂâßÂ¢ûÈïø‰ª•Âèä‰ºÅ‰∏öÁü•ÂêçÂ∫¶Ëøõ‰∏ÄÊ≠•ÊèêÂçáÔºåÂπ∂ÊúâÂä©‰∫éÊåñÊéòÊñ∞ÁöÑÂÆ¢Êà∑Áæ§‰ΩìÔºåÂ¢ûÂº∫‰∫ßÂìÅÁ≤òÊÄß„ÄÇËøôÁßçÁßØÊûÅÁöÑÂ∏ÇÂú∫ÂèçÂ∫îÂèØËÉΩÂØπË¥µÂ∑ûËåÖÂè∞ÁöÑËÇ°‰ª∑‰∫ßÁîüÊ≠£Èù¢ÂΩ±Âìç„ÄÇÁÑ∂ËÄåÔºåËÇ°‰ª∑ÁöÑËµ∞ÂäøËøò‰ºöÂèóÂà∞ÂÖ∂‰ªñÂõ†Á¥†ÁöÑÂΩ±ÂìçÔºåÂ¶ÇÊï¥‰ΩìÂ∏ÇÂú∫ÊÉÖÂÜµ„ÄÅÂÖ¨Âè∏Ë¥¢Âä°Ë°®Áé∞„ÄÅË°å‰∏öÁ´û‰∫âÁ≠â„ÄÇ
    >Êï¥‰ΩìÊù•ÁúãÔºåÊú™Êù•‰∫îÂ§©Ë¥µÂ∑ûËåÖÂè∞ÁöÑËÇ°‰ª∑ÂèØËÉΩ‰ºöÂá∫Áé∞1%Â∑¶Âè≥ÁöÑÂ¢ûÂπÖ„ÄÇ

# Benchmark

We release the [CFBenchmark-Basic](https://github.com/TongjiFinLab/CFBenchmark), a chinese finance benchmark, including 3917 financial texts spanning three aspects and eight tasks, for the evaluation of the financial text processing capability of LLMs in Chinese financial market.

CFBenchmark-Basic utilize two types of metrics to evaluate the performance of LLMs in the financial domain on our CFBenchmark-Basic. 
For recognition and classification tasks, we employe the **F1 score** as the evaluation metric, which balance the precision and recall.  
For the generation tasks, we utilize **cosine similarity** between the vectored representation of ground truth and generated answer as measure the generation ability.  Since there are usually different expressions with the similar meaning in our generation tasks, simply employing Rough-Score or BULE-socre is not reasonable. Specifically, the **bge-zh-v1.5** is assigned as the oracle model to generate the sentence embedding. We calculate evaluation scores for each sub-task individually and provide the average score for each category.

The best scores of LLMs (considering zero-shot and few-shot),as well as which of our model,  are demonstrated below:

| Model              | Size | Company   | Product   | R.Avg     | Industry  | Event     | Sentiment | C.Avg     | Summary   | Risk      | Suggestion | G.Avg     | Avg       |
| ------------------ | ---- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | ---------- | --------- | --------- |
| ChatGPT            | 20B  | 0.797     | 0.198     | 0.498     | 0.453     | 0.458     | 0.425     | 0.455     | 0.593     | 0.541     | 0.771      | 0.635     | 0.529     |
| ERNIE-Bot          | 260B | 0.807     | 0.300     | 0.533     | 0.408     | 0.350     | 0.186     | 0.315     | 0.715     | 0.590     | 0.716      | 0.673     | 0.507     |
| ERNIE-Bot-4        | -    | 0.819     | 0.417     | 0.618     | 0.418     | 0.358     | 0.375     | 0.384     | 0.721     | 0.629     | 0.718      | 0.689     | 0.564     |
| Falcon-7B          | 7B   | 0.671     | 0.168     | 0.420     | 0.169     | 0.132     | 0.250     | 0.184     | 0.302     | 0.301     | 0.246      | 0.283     | 0.296     |
| Falcon-7B-chat     | 7B   | 0.582     | 0.046     | 0.314     | 0.112     | 0.142     | 0.153     | 0.135     | 0.307     | 0.299     | 0.258      | 0.288     | 0.246     |
| bloomz-7B1         | 7B   | 0.765     | 0.166     | 0.465     | 0.252     | 0.154     | 0.394     | 0.267     | 0.451     | 0.371     | 0.462      | 0.428     | 0.387     |
| bloomz-7Bt1-mt     | 7B   | 0.751     | 0.157     | 0.454     | 0.087     | 0.182     | 0.380     | 0.216     | 0.425     | 0.379     | 0.396      | 0.400     | 0.357     |
| Qwen-7B            | 7B   | 0.780     | 0.357     | 0.569     | 0.480     | 0.335     | 0.379     | 0.398     | 0.750     | 0.505     | 0.713      | 0.656     | 0.541     |
| Qwen-Chat-7B       | 7B   | 0.763     | 0.360     | 0.562     | 0.400     | 0.367     | 0.265     | 0.344     | 0.548     | 0.307     | 0.379      | 0.411     | 0.439     |
| Qwen-14B           | 14B  | 0.805     | 0.421     | 0.613     | 0.481     | 0.350     | 0.385     | 0.405     | 0.754     | 0.608     | 0.717      | 0.693     | 0.570     |
| Qwen-Chat-14B      | 14B  | 0.814     | 0.442     | 0.628     | 0.382     | 0.400     | 0.350     | 0.377     | 0.732     | 0.478     | 0.736      | 0.649     | 0.551     |
| ChatGLM2-6B        | 6B   | 0.747     | 0.313     | 0.530     | 0.285     | 0.300     | 0.357     | 0.314     | 0.657     | 0.454     | 0.671      | 0.594     | 0.479     |
| Baichuan2-7B-Base  | 7B   | 0.672     | 0.340     | 0.506     | 0.342     | 0.490     | 0.480     | 0.437     | 0.739     | 0.619     | 0.751      | 0.703     | 0.549     |
| Baichuan2-7B-Chat  | 7B   | 0.757     | 0.402     | 0.579     | 0.425     | 0.475     | 0.323     | 0.408     | 0.725     | 0.648     | 0.732      | 0.702     | 0.563     |
| Baichuan2-13B-Base | 13B  | 0.781     | 0.330     | 0.555     | 0.436     | 0.496     | 0.477     | 0.470     | 0.725     | 0.503     | 0.747      | 0.658     | 0.561     |
| Baichuan2-13B-Chat | 13B  | 0.797     | 0.314     | 0.556     | 0.472     | 0.507     | 0.387     | 0.455     | 0.739     | 0.634     | 0.746      | 0.706     | 0.572     |
| InternLM-7B        | 7B   | 0.612     | 0.233     | 0.423     | 0.266     | 0.311     | 0.328     | 0.302     | 0.378     | 0.336     | 0.379      | 0.364     | 0.363     |
| InternLM-7B-Chat   | 7B   | 0.632     | 0.261     | 0.447     | 0.272     | 0.364     | 0.399     | 0.345     | 0.363     | 0.270     | 0.353      | 0.329     | 0.374     |
| InternLM-20B       | 20B  | 0.809     | 0.358     | 0.583     | 0.500     | 0.427     | 0.417     | 0.448     | 0.706     | 0.653     | 0.728      | 0.695     | 0.575     |
| InternLM-20B-Chat  | 20B  | 0.488     | 0.362     | 0.425     | 0.323     | 0.327     | 0.370     | 0.340     | 0.706     | 0.578     | 0.762      | 0.662     | 0.476     |
| CFGPT1-stf-LoRA    | 7B   | 0.820     | 0.414     | 0.617     | 0.569     | 0.729     | 0.769     | 0.689     | 0.745     | 0.584     | 0.609      | 0.646     | 0.650     |
| CFGPT1-sft-Full    | 7B   | **0.836** | **0.476** | **0.656** | **0.700** | **0.808** | **0.829** | **0.779** | **0.798** | **0.669** | **0.808**  | **0.758** | **0.731** |

More details can be found in [CFBenchmark-Basic](https://github.com/TongjiFinLab/CFBenchmark)

# Acknowledgements

CFGPT has referred to the following open-source projects. We want to express our gratitude and respect to the researchers of the projects.

- InternLM: https://github.com/InternLM/InternLM
- Firefly: https://github.com/yangjianxin1/Firefly
- FinGPT: https://github.com/AI4Finance-Foundation/FinGPT

# To-Do List

- [ ] Series of applications with CFGPT.
- [ ] Constructing more comprehensive training tasks and their corresponding databases.
- [ ] Continued improvement of the capabilities of CFGPT in more complex financial tasks.

# License

CFGPT is a research preview intended for non-commercial use only, subject to the model License of InternLM and the Terms of Use of the data generated by OpenAI. Please contact us if you find any potential violations. The code is released under the Apache License 2.0. 

# Citation

If you use the code or model of [**CFGPT**](https://arxiv.org/abs/2309.10654), please declare the reference with the following:

```
@misc{li2023cfgpt,
      title={CFGPT: Chinese Financial Assistant with Large Language Model}, 
      author={Jiangtong Li and Yuxuan Bian and Guoxuan Wang and Yang Lei and Dawei Cheng and Zhijun Ding and Changjun Jiang},
      year={2023},
      eprint={2309.10654},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
